
import os
import json
import requests
import sys
import threading
import webbrowser
import logging
import time
import asyncio
import edge_tts
if os.name == 'nt':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# --- GUI Support Check ---
try:
    import tkinter as tk
    from tkinter import ttk, scrolledtext, messagebox
    HAS_TK = True
except ImportError:
    HAS_TK = False
    print("Tkinter not found (Headless environment detected). GUI will be disabled.")
from datetime import datetime, timedelta, timezone
from flask import Flask, request, jsonify, make_response, send_file, Response, stream_with_context, send_from_directory
from flask_cors import CORS
import lunar_python
from lunar_python import Lunar, Solar

# --- FORCE IPV4 PATCH (Gemini Connectivity Fix) ---
import google.generativeai as genai
import socket
import urllib3.util.connection as urllib3_cn

def allowed_gai_family():
    return socket.AF_INET
urllib3_cn.allowed_gai_family = allowed_gai_family
# ------------------------------------------------

from master_book import MASTER_BOOK
from rule_engine import create_chart_from_dict, evaluate_rules, PALACE_NAMES

# --- Configuration & Constants Loading ---
def load_config():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(base_dir, 'config.json')
    defaults = {
        "server": {"host": "0.0.0.0", "port": 5000, "debug": False},
        "gemini": {
            "provider": "groq", 
            "api_key": "", 
            "groq_key": "",
            "model": "llama-3.1-8b-instant", 
            "temperature": 0.7, 
            "max_output_tokens": 3000
        },
        "ollama": {
            "enable": True,
            "url": "http://127.0.0.1:11434/api/generate",
            "model": "gemma2:2b"
        }
    }
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                for k, v in user_config.items():
                    if k in defaults and isinstance(v, dict): defaults[k].update(v)
                    else: defaults[k] = v
        except Exception as e:
            print(f"Error loading config.json: {e}")
    return defaults

def load_constants():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    const_path = os.path.join(base_dir, 'ziwei_constants.json')
    defaults = {
        "STEMS": ["ç”²", "ä¹™", "ä¸™", "ä¸", "æˆŠ", "å·±", "åºš", "è¾›", "å£¬", "ç™¸"],
        "BRANCHES": ["å­", "ä¸‘", "å¯…", "å¯", "è¾°", "å·³", "åˆ", "æœª", "ç”³", "é…‰", "æˆŒ", "äº¥"],
        "SI_HUA_TABLE": {}
    }
    if os.path.exists(const_path):
        try:
            with open(const_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                defaults.update(data)
        except Exception as e:
            print(f"Error loading ziwei_constants.json: {e}")
    return defaults

CONFIG = load_config()
CONSTANTS = load_constants()
STEMS = CONSTANTS['STEMS']
BRANCHES = CONSTANTS['BRANCHES']
SI_HUA_TABLE = CONSTANTS['SI_HUA_TABLE']

# --- Global Data Paths ---
CHAT_LOG_FILE = 'chat_history.json'
RECORD_FILE = 'user_records.json'

# --- Persistence Layer (JSON vs MongoDB) ---
MONGO_URI = os.environ.get("MONGO_URI") or CONFIG.get("mongo_uri")
USE_MONGODB = CONFIG.get("use_mongodb", True) # Default to True, but allow disabling
db = None
users_collection = None
chats_collection = None
MONGO_AVAILABLE = False

if MONGO_URI and USE_MONGODB:
    print(f"DEBUG: Found MONGO_URI environment variable (Length: {len(MONGO_URI)})") # Debug check
    # MongoDB connection setup
    try:
        import pymongo
        from pymongo import MongoClient
        print(f"DEBUG: Pymongo ç‰ˆæœ¬: {pymongo.version}")
        client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000, connectTimeoutMS=10000, socketTimeoutMS=15000)
        
        # Try to get default database, if fails (e.g. URI has no path), use 'fate_purple'
        try:
            db = client.get_database()
        except:
            db = client["fate_purple"]
        users_collection = db["user_records"]
        chats_collection = db["chat_history"]
        print(f"âœ… MongoDB å®¢æˆ¶ç«¯å·²é€£æ¥è³‡æ–™åº«: {db.name}")
        
        # REMOVED synchronous ping check to avoid blocking startup
        # client.admin.command('ping') 

        if "test" in db.name and not "?" in MONGO_URI: # Heuristic check
             print("è­¦å‘Š: é è¨­è³‡æ–™åº«ç‚º 'test'ã€‚æ‚¨å¯èƒ½éœ€è¦åœ¨ URI ä¸­æŒ‡å®šè³‡æ–™åº«åç¨±ã€‚")
        MONGO_AVAILABLE = True
    except Exception as e:
        import traceback
        print(f"âŒ MongoDB é€£ç·šå¤±æ•—ã€‚è©³ç´°éŒ¯èª¤:\n{traceback.format_exc()}")
        db = None
        users_collection = None
        chats_collection = None
        MONGO_AVAILABLE = False

# --- Google Sheets Integration ---
SHEETS_CREDENTIALS_FILE = 'credentials.json'
SPREADSHEET_ID = os.environ.get("SPREADSHEET_ID") or CONFIG.get("spreadsheet_id")
sheets_service = None

def get_sheets_service():
    global sheets_service
    if sheets_service: return sheets_service
    
    if os.path.exists(SHEETS_CREDENTIALS_FILE):
        try:
            # Load credentials and ensure private_key is correctly formatted
            with open(SHEETS_CREDENTIALS_FILE, 'r', encoding='utf-8') as f:
                info = json.load(f)
            
            from google.oauth2 import service_account
            from googleapiclient.discovery import build
            
            SCOPES = ['https://www.googleapis.com/auth/spreadsheets']
            creds = service_account.Credentials.from_service_account_info(info, scopes=SCOPES)
            sheets_service = build('sheets', 'v4', credentials=creds)
            print(f"âœ… Google è©¦ç®—è¡¨æœå‹™å·²åˆå§‹åŒ–")
            return sheets_service
        except Exception as e:
            print(f"âŒ Google è©¦ç®—è¡¨åˆå§‹åŒ–å¤±æ•—: {e}")
            return None
    return None

def append_to_sheet(sheet_name, row_data):
    service = get_sheets_service()
    if not service or not SPREADSHEET_ID: return
    
    try:
        range_name = f"{sheet_name}!A1"
        body = {'values': [row_data]}
        service.spreadsheets().values().append(
            spreadsheetId=SPREADSHEET_ID, range=range_name,
            valueInputOption="USER_ENTERED", body=body).execute()
    except Exception as e:
        err_msg = str(e)
        if "400" in err_msg and "not supported for this document" in err_msg:
            print(f"âŒ è©¦ç®—è¡¨ ID æ ¼å¼éŒ¯èª¤ (ID: {SPREADSHEET_ID})")
            if len(SPREADSHEET_ID) == 33:
                print("ğŸš¨ åµæ¸¬åˆ° ID ç‚º 33 å­—å…ƒï¼Œæ¥µå¤§æ©Ÿç‡æ˜¯è¢«æˆªæ–·äº†ï¼æ­£ç¢º ID é€šå¸¸ç‚º 44 å­—å…ƒã€‚")
                print("è«‹è‡³ config.json é‡æ–°è²¼ä¸Šå®Œæ•´çš„ Spreadsheet IDã€‚")
            else:
                print("æç¤ºï¼šè«‹æª¢æŸ¥ config.json ä¸­çš„ spreadsheet_id æ˜¯å¦æ­£ç¢ºä¸”ç‚ºæœ‰æ•ˆçš„è©¦ç®—è¡¨ï¼ˆéè³‡æ–™å¤¾ï¼‰ã€‚")
        else:
            print(f"âš ï¸ è©¦ç®—è¡¨å¯«å…¥éŒ¯èª¤ ({sheet_name}): {e}")


def load_json_file(filename):
    global MONGO_AVAILABLE
    # MongoDB Mode (with fallback)
    if users_collection is not None and MONGO_AVAILABLE:
        try:
            if filename == RECORD_FILE:
                return list(users_collection.find({}, {'_id': 0}))
            elif filename == CHAT_LOG_FILE:
                return list(chats_collection.find({}, {'_id': 0}).sort("timestamp", 1))
        except Exception as e:
            print(f"âš ï¸ Mongo è®€å–éŒ¯èª¤ ({e})ï¼Œåˆ‡æ›è‡³æœ¬åœ° JSON...")
            # If we hit a timeout, maybe disable Mongo for a while? 
            # For now, let's keep trying but logging is annoying if it happens every time.
            # Let's simple disable it for this session if it fails once to ensure speed.
            # MONGO_AVAILABLE = False # Uncomment to permanent disable after split failure
            pass

    # Local File Mode
    if os.path.exists(filename):
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è¼‰å…¥ {filename} éŒ¯èª¤: {e}")
    return []

def save_json_file(filename, data):
    global MONGO_AVAILABLE
    # MongoDB Mode (with fallback)
    if users_collection is not None and MONGO_AVAILABLE:
        try:
            if filename == RECORD_FILE and data:
                # Naive implementation: assume the last item is the new one
                users_collection.insert_one(data[-1])
                # Also save to local file for backup? Yes.
            elif filename == CHAT_LOG_FILE and data:
                 chats_collection.insert_one(data[-1])
        except Exception as e:
            print(f"âš ï¸ Mongo å¯«å…¥éŒ¯èª¤ ({e})ï¼Œåˆ‡æ›è‡³æœ¬åœ° JSON...")
            # MONGO_AVAILABLE = False # Uncomment to disable after failure
    
    # Local File Mode (Always save or fallback)
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"å„²å­˜ {filename} éŒ¯èª¤: {e}")

HIDDEN_INSIGHTS_FILE = 'hidden_insights.json'
def load_hidden_insights():
    if os.path.exists(HIDDEN_INSIGHTS_FILE):
        try:
            with open(HIDDEN_INSIGHTS_FILE, 'r', encoding='utf-8') as f: return json.load(f)
        except: return {}
    return {
        "report": "", "daily": "", "pastLife": "", "ritual": "", 
        "love": "", "finance": "", "bazi": "", "simple": "", "chat": ""
    }

def save_hidden_insights(data):
    with open(HIDDEN_INSIGHTS_FILE, 'w', encoding='utf-8') as f: json.dump(data, f, ensure_ascii=False, indent=2)

def log_chat(model, prompt, response, user_info=None):
    # In MongoDB mode, we don't need to load all logs just to append one.
    entry = {
        "timestamp": datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%dT%H:%M:%S'),
        "model": model,
        "prompt": prompt,
        "response": response
    }
    if user_info:
        entry.update(user_info)
    
    if db is not None and chats_collection is not None:
        chats_collection.insert_one(entry)
    else:
        logs = load_json_file(CHAT_LOG_FILE)
        logs.append(entry)
        save_json_file(CHAT_LOG_FILE, logs[-1000:]) # Keep last 1000

    # --- Google Sheets Export ---
    try:
        row = [
            entry.get("timestamp"),
            entry.get("user_name", ""),
            entry.get("gender", ""),
            entry.get("birth_date", ""),
            entry.get("birth_hour", ""),
            entry.get("lunar_date", ""),
            model,
            prompt,
            response
        ]
        threading.Thread(target=append_to_sheet, args=("Chats", row), daemon=True).start()
    except: pass

def get_location_from_ip(ip):
    """Resolve IP address to City/Region using ip-api.com"""
    if not ip or ip in ['127.0.0.1', 'localhost']:
        return "å°ç£ (æœ¬åœ°æ¸¬è©¦)"
    try:
        # ip-api.com (Free for non-commercial, 45 req/min)
        res = requests.get(f"http://ip-api.com/json/{ip}?fields=status,message,country,regionName,city", timeout=2).json()
        if res.get('status') == 'success':
            return f"{res.get('country')} {res.get('regionName')} {res.get('city')}"
    except:
        pass
    return "æœªçŸ¥åœ°é»"

def get_heavenly_timing():
    """Calculate current Chinese Zodiac Hour and Solar Term Context"""
    # Use timezone-aware datetime for UTC+8
    now = datetime.now(timezone(timedelta(hours=8)))
    hour = now.hour
    
    # 1. åäºŒæ™‚è¾°åˆ¤å®š
    branches = ["å­", "ä¸‘", "å¯…", "å¯", "è¾°", "å·³", "åˆ", "æœª", "ç”³", "é…‰", "æˆŒ", "äº¥"]
    # å­æ™‚æ˜¯ 23-01, ä¸‘æ™‚æ˜¯ 01-03...
    idx = (hour + 1) // 2 % 12
    branch_hour = branches[idx] + "æ™‚"
    
    # 2. ç¯€æ°£èˆ‡ç¯€æ…¶æ„Ÿæ‡‰ (ç°¡åŒ–é‚è¼¯ï¼šç›®å‰æ­£å€¼è¾²æ›†é¦¬å¹´æ–°æ˜¥)
    # åœ¨å¯¦éš›æ‡‰ç”¨ä¸­å¯ä»¥å¼•å…¥ lunar_python é€²è¡Œç²¾ç¢ºåˆ¤æ–·
    season_msg = "ç›®å‰æ­£å€¼ã€é¦¬å¹´æ–°æ˜¥ã€‘ä½³ç¯€æœŸé–“ï¼Œè¬è±¡æ›´æ–°ï¼Œå–œæ°£æ´‹æ´‹ã€‚"
    if 23 <= hour or hour < 5:
        time_advice = f"æ­¤åˆ»æ­£å€¼ã€Œ{branch_hour}ã€æ·±å¤œï¼Œè¬ç±Ÿä¿±å¯‚ï¼Œæ˜¯èˆ‡éˆé­‚å°è©±çš„æœ€ä½³æ™‚åˆ»ï¼Œä½†ä¹Ÿè«‹ç·£ä¸»æ³¨æ„ä¼‘æ¯ã€‚"
    elif 5 <= hour < 9:
        time_advice = f"æ­¤åˆ»æ—­æ—¥åˆå‡ï¼Œæ­£å€¼ã€Œ{branch_hour}ã€ï¼Œæœæ°£è“¬å‹ƒï¼Œåˆ©æ–¼è¦åŠƒæœªä¾†ã€‚"
    else:
        time_advice = f"æ­¤åˆ»æ™‚å€¼ã€Œ{branch_hour}ã€ã€‚"
        
    return f"{season_msg} {time_advice}"

# --- App Globals ---
app = Flask(__name__, static_folder='.', static_url_path='')
CORS(app)

# AI Priority & Key Pools (Supports multiple keys separated by comma)
def get_key_list(env_name, config_key):
    # Render or other PAAS will provide env vars, local relies on config.json
    val = os.environ.get(env_name) or CONFIG['gemini'].get(config_key, "")
    if isinstance(val, list): return val
    if not val: return []
    return [k.strip() for k in str(val).split(",") if k.strip()]

GROQ_KEYS = get_key_list("GROQ_API_KEY", "groq_key")
GEMINI_KEYS = get_key_list("GEMINI_API_KEY", "api_key")

GROQ_MODEL = "llama-3.1-8b-instant"
GEMINI_MODEL = "gemini-2.0-flash"
import random

# --- AI Engine Callers ---
def call_ollama_api(prompt, system_prompt=""):
    """å‘¼å«æœ¬åœ° Ollama API (æ ¹æ“š config.json è¨­å®š)"""
    # å¦‚æœæ˜¯åœ¨ Render ç­‰é›²ç«¯ç’°å¢ƒï¼Œé€šå¸¸ç„¡æ³•é€£ç·šåˆ°æœ¬åœ° Ollamaï¼Œç›´æ¥è·³é
    if os.environ.get('RENDER'): return None

    ollama_cfg = CONFIG.get('ollama', {})
    if not ollama_cfg.get('enable', True): return None

    try:
        url = ollama_cfg.get('url', "http://127.0.0.1:11434/api/generate")
        payload = {
            "model": ollama_cfg.get('model', "gemma2:2b"),
            "prompt": prompt,
            "system": system_prompt,
            "stream": False,
            "options": {"num_ctx": 4096, "temperature": 0.7}
        }
        res = requests.post(url, json=payload, timeout=2) # ç¸®çŸ­è¶…æ™‚æ™‚é–“ï¼Œé¿å…å¡é “
        if res.status_code == 200:
            return res.json().get("response")
    except Exception as e:
        # åƒ…åœ¨åµéŒ¯æ¨¡å¼é¡¯ç¤ºï¼Œé¿å…å¹²æ“¾ä¸»æ—¥èªŒ
        if CONFIG['server'].get('debug'): print(f"Ollama API é›¢ç·š: {e}")
    return None

def stream_groq_api(prompt, system_prompt=""):
    available_keys = list(GROQ_KEYS)
    random.shuffle(available_keys)
    
    for current_key in available_keys:
        try:
            from groq import Groq
            client = Groq(api_key=current_key)
            completion = client.chat.completions.create(
                model=GROQ_MODEL,
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}],
                temperature=0.7, max_tokens=3000, stream=True
            )
            for chunk in completion:
                content = chunk.choices[0].delta.content
                if content: yield content
            return
        except Exception as e:
            err_str = str(e)
            if "429" in err_str:
                print(f">>> Groq API (Key: {current_key[:10]}...) ç¹å¿™/é™æµï¼Œå˜—è©¦å‚™æ´é‡‘é‘°...")
                continue
            elif "401" in err_str or "Invalid API Key" in err_str:
                print(f"âŒ Groq API é‡‘é‘°å¤±æ•ˆ ({current_key[:10]}...)ï¼Œå·²å¾æ¸…å–®ç§»é™¤ã€‚")
                if current_key in GROQ_KEYS:
                    GROQ_KEYS.remove(current_key)
            else:
                print(f"Groq API éŒ¯èª¤: {e}")
                break

def call_groq_api(prompt, system_prompt=""):
    full_response = ""
    for chunk in stream_groq_api(prompt, system_prompt):
        full_response += chunk
    return full_response if full_response else None

def stream_gemini_api(prompt, system_prompt=""):
    available_keys = list(GEMINI_KEYS)
    random.shuffle(available_keys)
    
    for current_key in available_keys:
        try:
            genai.configure(api_key=current_key)
            model_instance = genai.GenerativeModel(GEMINI_MODEL)
            response = model_instance.generate_content(f"{system_prompt}\n\n{prompt}", stream=True)
            for chunk in response:
                if chunk.text: yield chunk.text
            return
        except Exception as e:
            err_str = str(e)
            if "429" in err_str:
                print(f">>> Gemini API (Key: {current_key[:10]}...) ç¹å¿™/é™æµï¼Œå˜—è©¦å‚™æ´é‡‘é‘°...")
                continue
            elif "401" in err_str or "Invalid API Key" in err_str or "API_KEY_INVALID" in err_str:
                 print(f"âŒ Gemini API é‡‘é‘°å¤±æ•ˆ ({current_key[:10]}...)ï¼Œå·²å¾æ¸…å–®ç§»é™¤ã€‚")
                 if current_key in GEMINI_KEYS:
                     GEMINI_KEYS.remove(current_key)
            else:
                print(f"Gemini API éŒ¯èª¤: {e}")
                break

def call_gemini_api(prompt, system_prompt=""):
    full_response = ""
    for chunk in stream_gemini_api(prompt, system_prompt):
        full_response += chunk
    return full_response if full_response else None

# --- UI Application Class ---
# --- UI Application Class ---
if HAS_TK:
    BaseClass = tk.Tk
else:
    BaseClass = object

class BackendApp(BaseClass):
    def __init__(self, flask_app):
        if not HAS_TK: return
        super().__init__()
        self.flask_app = flask_app
        self.title("ç´«å¾®å…«å­— Â· å¤©æ©Ÿå‘½è­œç³»çµ± [å…¨åŠŸèƒ½å¾Œç«¯ä¸­æ§å°]")
        self.geometry("1040x800")
        self.configure(bg="#1e1e1e")
        
        self.is_running = False
        self.ngrok_process = None
        self.ngrok_url = None

        self.setup_ui()
        self.setup_logging()
        
        # Start server automatically
        self.after(500, self.start_server)
        self.refresh_records()
        self.refresh_chats()

    def setup_ui(self):
        style = ttk.Style()
        style.theme_use('clam')
        style.configure("TFrame", background="#1e1e1e")
        style.configure("Panel.TFrame", background="#252526")
        style.configure("TLabel", background="#1e1e1e", foreground="#d4d4d4", font=("Microsoft JhengHei", 10))
        style.configure("Header.TLabel", background="#252526", foreground="#ffffff", font=("Microsoft JhengHei", 12, "bold"))
        style.configure("TNotebook", background="#1e1e1e", borderwidth=0)
        style.configure("TNotebook.Tab", background="#2d2d2d", foreground="#999999", padding=[15, 5], font=("Microsoft JhengHei", 10))
        style.map("TNotebook.Tab", background=[("selected", "#3b82f6")], foreground=[("selected", "#ffffff")])

        # Header
        header = ttk.Frame(self, style="Panel.TFrame", padding=15)
        header.pack(fill="x")
        ttk.Label(header, text="ç´«å¾®å¤©æ©Ÿ Â· å¾Œç«¯ä¸­æ§å° (V2.5 é›™å¼•æ“ç‰ˆ)", style="Header.TLabel").pack(side="left")

        # Tabs
        self.notebook = ttk.Notebook(self, style="TNotebook")
        self.notebook.pack(fill="both", expand=True, padx=5, pady=5)

        # Tab 1: Monitor
        self.tab_monitor = ttk.Frame(self.notebook, style="TFrame")
        self.notebook.add(self.tab_monitor, text="  ä¼ºæœå™¨ç›£æ§  ")
        self.setup_monitor_tab()

        # Tab 2: Records
        self.tab_records = ttk.Frame(self.notebook, style="TFrame")
        self.notebook.add(self.tab_records, text="  ä½¿ç”¨è€…åå†Š  ")
        self.setup_records_tab()

        # Tab 3: Chats
        self.tab_chats = ttk.Frame(self.notebook, style="TFrame")
        self.notebook.add(self.tab_chats, text="  AI å°è©±ç´€éŒ„  ")
        self.setup_chats_tab()

        # Tab 4: Ngrok
        self.tab_ngrok = ttk.Frame(self.notebook, style="TFrame")
        self.notebook.add(self.tab_ngrok, text="  é ç«¯é€£ç·š (Ngrok)  ")
        self.setup_ngrok_tab()

    def setup_monitor_tab(self):
        toolbar = ttk.Frame(self.tab_monitor, padding=10)
        toolbar.pack(fill="x")
        tk.Button(toolbar, text="é–‹å•Ÿç¶²é  (Browser)", command=lambda: webbrowser.open("http://localhost:5000/"), 
                 bg="#3b82f6", fg="white", font=("Microsoft JhengHei", 10, "bold"), padx=15).pack(side="left", padx=5)
        tk.Button(toolbar, text="æ¸…ç©ºæ—¥èªŒ", command=lambda: self.txt_log.delete("1.0", "end"), 
                 bg="#4b5563", fg="white", font=("Microsoft JhengHei", 9)).pack(side="left", padx=5)
        tk.Button(toolbar, text="é—œé–‰ç³»çµ±", command=self.quit_app, 
                 bg="#ef4444", fg="white", font=("Microsoft JhengHei", 9, "bold"), padx=10).pack(side="right", padx=5)

        self.txt_log = scrolledtext.ScrolledText(self.tab_monitor, bg="black", fg="#00ff00", font=("Consolas", 10), insertbackground="white")
        self.txt_log.pack(fill="both", expand=True, padx=10, pady=10)

    def setup_records_tab(self):
        toolbar = ttk.Frame(self.tab_records, padding=10)
        toolbar.pack(fill="x")
        tk.Button(toolbar, text="é‡æ–°æ•´ç†åå†Š", command=self.refresh_records, bg="#3b82f6", fg="white").pack(side="left")

        cols = ("time", "name", "gender", "birth", "lunar")
        titles = ("éŒ„å…¥æ™‚é–“", "å§“å", "æ€§åˆ¥", "ç”Ÿæ—¥", "è¾²æ›†")
        self.tree_records = ttk.Treeview(self.tab_records, columns=cols, show='headings')
        for i, c in enumerate(cols): self.tree_records.heading(c, text=titles[i])
        self.tree_records.pack(fill="both", expand=True, padx=10, pady=10)

    def setup_chats_tab(self):
        paned = tk.PanedWindow(self.tab_chats, orient="vertical", bg="#1e1e1e", sashwidth=4)
        paned.pack(fill="both", expand=True, padx=10, pady=10)

        top = ttk.Frame(paned)
        paned.add(top, height=300)
        tk.Button(top, text="é‡æ–°æ•´ç†å°è©±", command=self.refresh_chats, bg="#3b82f6", fg="white").pack(anchor="w", pady=5)
        
        cols = ("time", "model", "prompt")
        titles = ("å°è©±æ™‚é–“", "AI æ¨¡å‹", "æå•å…§å®¹æ‘˜è¦")
        self.tree_chats = ttk.Treeview(top, columns=cols, show='headings')
        for i, c in enumerate(cols): self.tree_chats.heading(c, text=titles[i])
        self.tree_chats.pack(fill="both", expand=True)
        self.tree_chats.bind("<<TreeviewSelect>>", self.on_chat_select)

        self.txt_chat_detail = scrolledtext.ScrolledText(paned, bg="#2d2d2d", fg="white", font=("Microsoft JhengHei", 10))
        paned.add(self.txt_chat_detail)

    def setup_ngrok_tab(self):
        frame = ttk.Frame(self.tab_ngrok, padding=30)
        frame.pack(fill="both", expand=True)
        ttk.Label(frame, text="Ngrok é ç«¯ç©¿é€æœå‹™", font=("Microsoft JhengHei", 14, "bold")).pack(pady=10)
        
        self.btn_ngrok = tk.Button(frame, text="å•Ÿå‹• Ngrok éš§é“", command=self.toggle_ngrok, 
                                bg="#8b5cf6", fg="white", font=("Microsoft JhengHei", 11, "bold"), padx=20, pady=10)
        self.btn_ngrok.pack(pady=20)
        
        self.lbl_ngrok = ttk.Label(frame, text="ç‹€æ…‹: æœªå•Ÿå‹•")
        self.lbl_ngrok.pack()
        
        self.ent_ngrok = ttk.Entry(frame, font=("Consolas", 11), width=50)
        self.ent_ngrok.pack(pady=10)

    def refresh_records(self):
        for i in self.tree_records.get_children(): self.tree_records.delete(i)
        for r in reversed(load_json_file(RECORD_FILE)):
            self.tree_records.insert("", "end", values=(r.get("timestamp","")[:16], r.get("name"), r.get("gender"), r.get("birth_date"), r.get("lunar_date")))

    def refresh_chats(self):
        for i in self.tree_chats.get_children(): self.tree_chats.delete(i)
        self.chat_cache = load_json_file(CHAT_LOG_FILE)
        for idx, c in enumerate(reversed(self.chat_cache)):
            self.tree_chats.insert("", "end", iid=str(len(self.chat_cache)-1-idx), values=(c.get("timestamp","")[:19], c.get("model"), c.get("prompt")[:50]))

    def on_chat_select(self, e):
        sel = self.tree_chats.selection()
        if not sel: return
        c = self.chat_cache[int(sel[0])]
        self.txt_chat_detail.configure(state="normal")
        self.txt_chat_detail.delete("1.0", "end")
        info = f"ã€ç·£ä¸»ã€‘: {c.get('user_name','?')} | {c.get('gender','')} | {c.get('birth_date','')} {c.get('birth_hour','')} | {c.get('lunar_date','')}\n"
        self.txt_chat_detail.insert("1.0", f"{info}\nã€æå•ã€‘:\n{c.get('prompt')}\n\nã€å›ç­”ã€‘:\n{c.get('response')}")
        self.txt_chat_detail.configure(state="disabled")

    def toggle_ngrok(self):
        if self.ngrok_process:
            self.ngrok_process.terminate(); self.ngrok_process = None
            self.btn_ngrok.config(text="å•Ÿå‹• Ngrok éš§é“", bg="#8b5cf6")
            self.lbl_ngrok.config(text="ç‹€æ…‹: å·²åœæ­¢")
        else:
            try:
                self.ngrok_process = subprocess.Popen(["ngrok", "http", "5000"], creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0)
                self.btn_ngrok.config(text="åœæ­¢ Ngrok éš§é“", bg="#ef4444")
                threading.Thread(target=self.wait_ngrok, daemon=True).start()
            except: messagebox.showerror("éŒ¯èª¤", "æ‰¾ä¸åˆ° ngrok.exeï¼Œè«‹ç¢ºä¿å·²å®‰è£ä¸¦åŠ å…¥ PATH")

    def wait_ngrok(self):
        time.sleep(3)
        try:
            res = requests.get("http://127.0.0.1:4040/api/tunnels").json()
            url = res['tunnels'][0]['public_url']
            self.after(0, lambda: (self.ent_ngrok.delete(0, "end"), self.ent_ngrok.insert(0, url), self.lbl_ngrok.config(text="ç‹€æ…‹: åœ¨ç·š (Online)", foreground="#4ade80")))
        except: self.after(0, lambda: self.lbl_ngrok.config(text="ç‹€æ…‹: å–å¾—ç¶²å€å¤±æ•—"))

    def setup_logging(self):
        class Redir:
            def __init__(self, widget): self.widget = widget
            def write(self, s): self.widget.after(0, lambda: (self.widget.insert("end", s), self.widget.see("end")))
            def flush(self): pass
        sys.stdout = sys.stderr = Redir(self.txt_log)

    def start_server(self):
        t = threading.Thread(target=lambda: self.flask_app.run(host="0.0.0.0", port=5000, debug=False, use_reloader=False), daemon=True)
        t.start()
        print("Flask ä¼ºæœå™¨å·²å•Ÿå‹•æ–¼ http://localhost:5000")

    def quit_app(self):
        if self.ngrok_process: self.ngrok_process.terminate()
        if messagebox.askokcancel("é€€å‡º", "ç¢ºå®šè¦é—œé–‰å…¨ç³»çµ±å—ï¼Ÿ"): self.destroy(); sys.exit(0)

# --- Flask Routes ---
@app.route('/')
def index(): return send_file('fate.html')

@app.route('/admin')
def admin_page(): return send_file('admin.html')

@app.route('/api/db_check')
def db_check():
    sheets_ok = False
    try:
        if get_sheets_service() and SPREADSHEET_ID: sheets_ok = True
    except: pass

    status = {
        "mongo_uri_set": bool(MONGO_URI),
        "db_connected": db is not None,
        "users_collection": users_collection is not None,
        "db_name": db.name if db is not None else None,
        "google_sheets_connected": sheets_ok
    }
    return jsonify(status)

@app.route('/api/admin/data')
def get_admin_data():
    # Detect if we should use Mongo directly for counts/recent to avoid timeouts
    if users_collection is not None and MONGO_AVAILABLE:
        try:
            records_count = users_collection.count_documents({})
            chats_count = chats_collection.count_documents({})
            records = list(users_collection.find({}, {'_id': 0}).sort("timestamp", -1).limit(50))
            chats = list(chats_collection.find({}, {'_id': 0}).sort("timestamp", -1).limit(50))
        except Exception as e:
            print(f"âš ï¸ Mongo Admin Data è®€å–å¤±æ•—: {e}")
            records_count = 0
            chats_count = 0
            records = []
            chats = []
    else:
        # Local JSON Fallback (only for small files)
        full_records = load_json_file(RECORD_FILE)
        full_chats = load_json_file(CHAT_LOG_FILE)
        records_count = len(full_records)
        chats_count = len(full_chats)
        records = list(reversed(full_records[-50:]))
        chats = list(reversed(full_chats[-50:]))
    
    # Determine DB Status text
    # Determine DB Status text
    status_parts = []
    
    if USE_MONGODB and MONGO_URI:
        if db is not None:
             status_parts.append(f"MongoDB ({db.name})")
        else:
             status_parts.append("MongoDB (é€£ç·šå¤±æ•—)")
    
    if get_sheets_service() and SPREADSHEET_ID:
        status_parts.append("Google è©¦ç®—è¡¨")
        
    if not status_parts:
        status_parts.append("æœ¬åœ° JSON")
        
    status_text = " + ".join(status_parts)
    
    return jsonify({
        "records_count": records_count,
        "chats_count": chats_count,
        "records": records,
        "chats": chats,
        "status": "Online",
        "uptime": "Running",
        "db_status": status_text
    })

@app.route('/api/admin/hidden_insights', methods=['GET', 'POST'])
def handle_hidden_insights():
    if request.method == 'GET':
        return jsonify(load_hidden_insights())
    
    data = request.json or {}
    insights = load_hidden_insights()
    insights.update(data)
    save_hidden_insights(insights)
    return jsonify({"success": True})

@app.route('/<path:filename>')
def serve_static(filename):
    if filename.lower().endswith(('.png', '.ico', '.jpg', '.jpeg', '.html', '.css', '.js', '.json')):
        if os.path.exists(filename): return send_file(filename)
    return "Not Found", 404

@app.route('/api/save_record', methods=['POST', 'OPTIONS'])
def save_record():
    if request.method == 'OPTIONS':
        resp = make_response(); resp.headers.add("Access-Control-Allow-Origin", "*"); resp.headers.add("Access-Control-Allow-Headers", "*"); return resp
    data = request.json or {}
    record = {
        "timestamp": datetime.now(timezone(timedelta(hours=8))).strftime('%Y-%m-%dT%H:%M:%S'), "name": data.get("name", "Unknown"),
        "gender": data.get("gender"), "birth_date": data.get("birth_date"),
        "birth_hour": data.get("birth_hour"), "lunar_date": data.get("lunar_date")
    }
    
    if db is not None and users_collection is not None:
        users_collection.insert_one(record)
    else:
        recs = load_json_file(RECORD_FILE); recs.append(record); save_json_file(RECORD_FILE, recs)

    # --- Local Excel Fallback ---
    try:
        import pandas as pd
        df = pd.DataFrame(recs)
        df.rename(columns={
            "timestamp": "ç´€éŒ„æ™‚é–“", "name": "å§“å", "gender": "æ€§åˆ¥",
            "birth_date": "åœ‹æ›†ç”Ÿæ—¥", "birth_hour": "æ™‚è¾°(æ”¯)", "lunar_date": "è¾²æ›†æ—¥æœŸ"
        }, inplace=True)
        excel_path = 'user_records.xlsx'
        df.to_excel(excel_path, index=False, engine='openpyxl')
        print(f"ğŸ’¾ å·²åŒæ­¥å‚™ä»½è‡³æœ¬åœ° Excel: {excel_path}")
    except Exception as e:
        if "pandas" not in str(e).lower(): 
            print(f"âš ï¸ æœ¬åœ° Excel å‚™ä»½å¤±æ•—: {e}")

    # --- Google Sheets Export ---
    try:
        row = [
            record.get("timestamp"),
            record.get("name"),
            record.get("gender"),
            record.get("birth_date"),
            record.get("birth_hour"),
            str(record.get("lunar_date"))
        ]
        threading.Thread(target=append_to_sheet, args=("Users", row), daemon=True).start()
    except: pass
        
    return make_response(jsonify({"success": True}), 200, {"Access-Control-Allow-Origin": "*"})

@app.route('/api/chat', methods=['POST', 'OPTIONS'])
def chat():
    if request.method == 'OPTIONS':
        resp = make_response(); resp.headers.add("Access-Control-Allow-Origin", "*"); resp.headers.add("Access-Control-Allow-Headers", "*"); return resp
    
    data = request.json or {}
    user_prompt = data.get('prompt', '')
    client_sys = data.get('system_prompt', '')
    gender = data.get('gender', 'M')
    chart_data = data.get('chart_data')
    
    # Extract User Identity
    user_info = {
        "user_name": data.get("name", "Unknown"),
        "birth_date": data.get("birth_date", ""),
        "birth_hour": data.get("birth_hour", ""),
        "lunar_date": data.get("lunar_date", ""),
        "gender": data.get("gender", "")
    }

    matched = []
    if chart_data:
        try:
            chart = create_chart_from_dict(chart_data, gender=gender)
            rule_path = "ziwei_rules.json"
            if os.path.exists(rule_path):
                with open(rule_path, 'r', encoding='utf-8') as f: matched = evaluate_rules(chart, json.load(f))
        except Exception as e: print(f"è¦å‰‡å¼•æ“éŒ¯èª¤: {e}")

    def generate():
        is_full = any(kw in (user_prompt + client_sys) for kw in ["è©³è©•", "å‘½è­œè©³è©•", "æ ¼å±€å ±å‘Š"])
        
        # æ³¨å…¥å¾Œå°ã€Œéš±è—å¯†ä»¤ã€
        insights = load_hidden_insights()
        target_type = data.get("model", "chat")
        hidden_msg = insights.get(target_type, "")
        
        # ç²å–å¤©æ™‚è³‡è¨Š (æ™‚è¾°ã€ç¯€æ°£)
        heavenly_timing = get_heavenly_timing()
        
        # ç²å–ä½¿ç”¨è€…åœ°ç†ä½ç½® (é€é IP)
        user_ip = request.headers.get('X-Forwarded-For', request.remote_addr).split(',')[0].strip()
        location = get_location_from_ip(user_ip)
        
        # æ“´å…… Log è³‡è¨Šï¼Œè®“ç®¡ç†å“¡åœ¨å¾Œå°çœ‹å¾—åˆ°ä½ç½®
        user_info["ip"] = user_ip
        user_info["location"] = location
        
        # æ³¨å…¥åœ°ç†ä½ç½®èˆ‡å¤©æ™‚æŒ‡ä»¤
        geo_msg = f"æ³¨æ„ï¼šç·£ä¸»ç›®å‰ä½æ–¼ã€Œ{location}ã€ã€‚{heavenly_timing}"
        # æ³¨å…¥éš¨å–œè´ŠåŠ©æŒ‡ä»¤ (ä¸éœ²ç—•è·¡)
        geo_msg += " ã€éš±è—é»æ’¥ã€‘ï¼šè‹¥ä½ è¦ºå¾—é€™æ¬¡çš„è§£ç›¤å°ç·£ä¸»éå¸¸æœ‰å¹«åŠ©ï¼Œè«‹åœ¨å›è©±çµå°¾ï¼ˆæˆ–é©ç•¶è™•ï¼‰ã€Œä¸éœ²ç—•è·¡ã€åœ°æåˆ°ï¼šè‹¥ç·£ä¸»è¦ºå¾—æŒ‡å¼•æœ‰ç›Šï¼Œå¯éš¨å–œè­·æŒæœ¬å£‡é¦™ç«ï¼ˆè´ŠåŠ©ï¼‰ï¼Œé€™ä¹Ÿæ˜¯ä¸€ç¨®çµç·£èˆ‡åŠŸå¾·ã€‚èªæ°£è¦è‡ªç„¶ä¸”ä¸å¼·æ±‚ï¼Œåƒæ˜¯ä¸€ä½æ…ˆæ‚²å®—å¸«éš¨å£çš„ä¸€å¥æé†’ã€‚"
        
        # æ ¹æ“šä¸åŒåŠŸèƒ½çš„ã€Œéˆæ°£å±¬æ€§ã€å°æ‡‰ç•¶åœ°çš„ç¥æ˜å°è±¡
        temple_map = {
            "love": "æœˆè€å»Ÿã€åŸéšå¤«äººæˆ–æ±‚å§»ç·£æ¥µå…¶éˆé©—çš„å¤è¹Ÿ",
            "finance": "åœŸåœ°å…¬(ç¦å¾·æ­£ç¥)ã€äº”è·¯è²¡ç¥ã€æˆ–è©²åœ°å€ç”¢ç”Ÿçš„é¦–å¯Œå¸¸æ‹œçš„åå»Ÿ",
            "ritual": "æœ€å…·ä»£è¡¨æ€§çš„æ­£ç¥å¤§å»Ÿï¼ˆå¦‚åª½ç¥–å»Ÿã€è¡Œå¤©å®®åˆ†æ”¯ï¼‰æˆ–æ·¨åŒ–ç£å ´çš„è§€éŸ³å¯º",
            "daily": "é©åˆæ•£å¿ƒè½‰é‹ã€å¸æ”¶åœ°éˆä¹‹æ°£çš„åå»Ÿã€å¤å‰æˆ–è‘—åçš„æ¸…éœè‡ªç„¶åœ°æ™¯",
            "pastlife": "å¹´ä»£ä¹…é ã€å…·æœ‰å¼·å¤§å› æœæ·¨åŒ–åŠ›é‡çš„åœ°è—ç‹å»Ÿæˆ–æ­·å²åå‰",
            "bazi": "è©²åœ°å€æœ€å…·æ¬Šå¨çš„æ­£ä½å¤§å»Ÿï¼Œç”¨ä»¥å¹³è¡¡å‘½ç†äº”è¡Œæ°£å ´",
            "report": "ç•¶åœ°çš„ä¿¡ä»°ä¸­å¿ƒï¼Œå¦‚ç•¶åœ°çš„å¤©åå®®ã€ä¿å®‰å®®ã€æˆ–æœ€å—ç•¶åœ°ä¿¡çœ¾æ¨å´‡çš„ã€Œå®ˆè­·ç¥ã€å»Ÿå®‡",
            "simple": "é¦™ç«é¼ç››ã€æ­£èƒ½é‡æ°£å ´å¼·å¤§çš„ååˆ©èˆ‡å¹³å®‰å®ˆè­·å»Ÿå®‡",
            "chat": "è©²åŸå¸‚æœ€å…·ä»£è¡¨æ€§çš„æ–‡åŒ–æ·±åº¦åå»Ÿ"
        }
        
        target_key = target_type.lower()
        target_recommend = temple_map.get(target_key, "å‘¨é‚Šå…·å‚™æ­£èƒ½é‡æ°£å ´ã€é¦™ç«é¼ç››çš„åé–€å¤§å»Ÿ")
        
        is_concise_mode = target_type in ["daily", "ritual", "pastLife", "love", "finance"]
        
        # æ³¨å…¥åœ°ç†ä½ç½®èˆ‡å¤©æ™‚æŒ‡ä»¤
        geo_msg = f"æ³¨æ„ï¼šç·£ä¸»ç›®å‰ä½æ–¼ã€Œ{location}ã€ã€‚{heavenly_timing}"
        
        if not is_concise_mode:
            # æ³¨å…¥éš¨å–œè´ŠåŠ©æŒ‡ä»¤ (ä¸éœ²ç—•è·¡)
            geo_msg += " ã€éš±è—é»æ’¥ã€‘ï¼šè‹¥ä½ è¦ºå¾—é€™æ¬¡çš„è§£ç›¤å°ç·£ä¸»éå¸¸æœ‰å¹«åŠ©ï¼Œè«‹åœ¨å›è©±çµå°¾ï¼ˆæˆ–é©ç•¶è™•ï¼‰æåˆ°ï¼šè‹¥ç·£ä¸»è¦ºå¾—æŒ‡å¼•æœ‰ç›Šï¼Œå¯éš¨å–œè­·æŒæœ¬å£‡é¦™ç«ï¼ˆè´ŠåŠ©ï¼‰ã€‚"
            geo_msg += f" \nåœ¨åˆ†æèˆ‡æŒ‡å¼•ä¸­ï¼Œè«‹é‡å°ã€Œ{location}ã€å‘¨é‚Šï¼Œç²¾æº–æ¨è–¦ç›¸é—œçš„ã€{target_recommend}ã€ã€‚"
            geo_msg += " \nã€æ¥µé‡è¦æŒ‡ä»¤ã€‘ï¼šçµ•å°ç¦æ­¢æåŠå…·é«”åŸå¸‚åã€‚è«‹ä»¥å®—å¸«èªæ°£ï¼Œç›´æ¥èªªå‡ºå»Ÿå®‡åç¨±ï¼Œé¡¯å¾—åƒæ˜¯å¤©æ©Ÿé»æ’¥ã€‚"
        else:
            # æ¥µç°¡æ¨¡å¼ï¼šåƒ…æä¾›åœ°é»åƒè€ƒï¼Œä¸è¦æ±‚æ“¬äººåŒ–èªæ°£
            geo_msg += f" (æ¨è–¦å‘¨é‚Šã€{target_recommend}ã€)"

        # å‹•æ…‹ç³»çµ±æç¤ºè©ï¼šå¹³å¸¸å°è©±ä¸å¸¶ç§˜å·ä»¥ç¯€çœ Token
        # é‡è¦ï¼šå°‡å‰ç«¯æŒ‡å®šçš„ client_sys æ”¾åœ¨æœ€å¾Œï¼Œä¸¦åŠ ä¸Šæœ€é«˜æŒ‡ä»¤æ¨™ç±¤ï¼Œç¢ºä¿ AI åš´æ ¼åŸ·è¡Œæ ¼å¼è¦æ±‚
        priority_tag = "\nã€æœ€é«˜å„ªå…ˆæ¬ŠæŒ‡ä»¤ï¼šè«‹ç›´æ¥åŸ·è¡Œä»¥ä¸‹æ ¼å¼èˆ‡å…§å®¹è¦æ±‚ï¼Œç¦æ­¢å¤šé¤˜æè¿°ã€‘\n"
        
        if is_full:
            final_system_prompt = f"ä½ æ˜¯ã€ç´«å¾®å¤©æ©Ÿé“é•·ã€‘ï¼Œå‘½ç†å®—å¸«ã€‚\n{geo_msg}\n{hidden_msg}{priority_tag}{client_sys}\n\nã€ç´«å¾®å¿ƒæ³•ç§˜å·ã€‘\n{MASTER_BOOK}"
        else:
            final_system_prompt = f"ä½ æ˜¯ã€ç´«å¾®å¤©æ©Ÿé“é•·ã€‘ï¼Œèªæ°£å„ªé›…æ…ˆæ‚²ã€‚\n{geo_msg}\n{hidden_msg}{priority_tag}{client_sys}"

        # Updated AI Caller with Streaming Support
        def stream_ai(p, s):
            print(f">>> AI è«‹æ±‚ (Prompt: {p[:15]}...)")
            
            # Phase 1: Local Ollama
            if not os.environ.get('RENDER'):
                res = call_ollama_api(p, s)
                if res and len(res.strip()) > 5: 
                    yield res
                    return

            provider = CONFIG.get('gemini', {}).get('provider', 'gemini').lower()
            
            def try_groq_flow():
                has_content = False
                for chunk in stream_groq_api(p, s):
                    has_content = True
                    yield chunk
                return has_content

            def try_gemini_flow():
                has_content = False
                for chunk in stream_gemini_api(p, s):
                    has_content = True
                    yield chunk
                return has_content

            if provider == 'groq':
                print(">>> å„ªå…ˆå˜—è©¦ Groq ä¸²æµæ¨¡å¼...")
                if not (yield from try_groq_flow()):
                    print(">>> Groq å¤±æ•—ï¼Œå˜—è©¦ Gemini å‚™æ´...")
                    if not (yield from try_gemini_flow()):
                        yield "é€£ç·šå¿™ç¢Œï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"
            else:
                print(">>> å„ªå…ˆå˜—è©¦ Gemini ä¸²æµæ¨¡å¼...")
                if not (yield from try_gemini_flow()):
                    print(">>> Gemini å¤±æ•—ï¼Œå˜—è©¦ Groq å‚™æ´...")
                    if not (yield from try_groq_flow()):
                        yield "é€£ç·šå¿™ç¢Œï¼Œè«‹ç¨å¾Œå†è©¦ã€‚"

        if matched and is_full:
            yield "ã€å¤©æ©Ÿåˆ†ææˆåŠŸ...ã€‘å®—å¸«æ­£åœ¨ç‚ºæ‚¨è©³æ‰¹æ ¼å±€...\n\n"
            titles = {"A": "ã€ç¬¬ä¸€ç« ï¼šæ˜Ÿæ›œåå®ˆèˆ‡ç¥ç…ç‰¹å¾µã€‘", "B": "ã€ç¬¬äºŒç« ï¼šå‘½å®®å®®å¹²é£›åŒ–ã€‘", "C": "ã€ç¬¬ä¸‰ç« ï¼šå®®ä½é–“çš„äº¤äº’é£›åŒ–ã€‘"}
            
            all_chapter_summaries = "" 
            chapter_sys = "ä½ æ˜¯ã€ç´«å¾®å¤©æ©Ÿé“é•·ã€‘ï¼Œå‘½ç†å®—å¸«ã€‚è«‹é‡å°æ­¤å‘½ç›¤æ ¼å±€ï¼Œç›´æ¥çµ¦äºˆç·£ä¸»ç™½è©±ä¸”æ·±å…¥çš„å‘½ç†åˆ†æã€‚èªæ°£è¦æ¬Šå¨ä¸”æ…ˆæ‚²ï¼Œåˆ‡å‹¿åŒ…å«ã€Œæœ¬ç« ç¯€ã€ã€ã€Œç¶œä¸Šæ‰€è¿°ã€ã€ã€Œè¦å‰‡ã€ç­‰ç”Ÿç¡¬è©å½™ã€‚è«‹ç›´æ¥åˆ‡å…¥é‡é»ï¼Œåˆ†æå‰å‡¶ã€‚"

            for g_code, g_title in titles.items():
                items = [r for r in matched if r.get("rule_group") == g_code]
                if items:
                    yield f"\n{g_title}\n" + "-"*35 + "\n"
                    
                    chapter_content = ""
                    for r in items[:15]: 
                        rule_txt = f"â— ã€{r.get('detected_palace_names','å…¨ç›¤')}ã€‘{r.get('description')}ï¼š{r.get('text')}"
                        yield rule_txt + "\n"
                        chapter_content += rule_txt + "\n"
                    
                    yield f"\nğŸ’¡ å¤§å¸«ç« ç¯€æ‰¹è¨»ï¼š\n"
                    explain_prompt = f"ç« ç¯€ï¼š{g_title}\nåŒ…å«è¦å‰‡ï¼š\n{chapter_content}\nè«‹çµ¦äºˆæœ¬ç« ç¯€çš„ç¶œåˆå‘½ç†è§£è®€ã€‚"
                    
                    # Use streaming for chapter explanations too
                    explanation_accum = ""
                    for chunk in stream_ai(explain_prompt, chapter_sys):
                        yield chunk
                        explanation_accum += chunk
                    yield "\n\n"
                    
                    summary_snapshot = explanation_accum[:250] + "..." if len(explanation_accum) > 250 else explanation_accum
                    all_chapter_summaries += f"### {g_title} é‡é»æ‘˜è¦ï¼š\n{summary_snapshot}\n\n"
            
            if all_chapter_summaries:
                yield "="*45 + "\nã€å¤©æ©Ÿåˆ¤èª Â· å‘½ç†çµ‚æ¥µç¸½çµã€‘\n"
                
                mini_final_sys = "ä½ æ˜¯ã€ç´«å¾®å¤©æ©Ÿé“é•·ã€‘ï¼Œå‘½ç†å®—å¸«ã€‚è«‹æ ¹æ“šå‘½ç›¤æ‘˜è¦çµ¦äºˆç·£ä¸»æœ€å¾Œçš„å»ºè­°ï¼ˆ300å­—ï¼‰ã€‚è«‹ç”¨ç™½è©±æ–‡ï¼Œèªæ°£æ…ˆæ‚²ï¼Œç›´æ¥çµ¦äºˆäººç”ŸæŒ‡å¼•ã€‚"
                final_prompt = f"ä»¥ä¸‹æ˜¯ç·£ä¸»çš„å‘½ç›¤ç« ç¯€æ‘˜è¦ï¼š\n{all_chapter_summaries}\n\nç”¨æˆ¶æå•ï¼š{user_prompt}\n\nè«‹åšæœ€å¾Œçš„ç¸½çµèˆ‡å»ºè­°ï¼Œæ¯é‡åˆ°å¥è™Ÿè«‹æ›è¡Œã€‚"
                
                final_accum = ""
                for chunk in stream_ai(final_prompt, mini_final_sys):
                     yield chunk
                     final_accum += chunk
            else:
                yield "ç„¡æ³•ç”Ÿæˆè¶³å¤ è³‡è¨Šä»¥é€²è¡Œç¸½çµã€‚"
            
            log_chat("Hybrid-Report-Chapter", user_prompt, "Detailed report generated.", user_info)
        else:
            # Standard Streaming Chat
            full_response = ""
            for chunk in stream_ai(user_prompt, final_system_prompt):
                if chunk:
                    yield chunk
                    full_response += chunk
            
            log_chat(data.get("model", "Hybrid-Stream"), user_prompt, full_response, user_info)

    return Response(stream_with_context(generate()), content_type='text/plain; charset=utf-8', headers={"Access-Control-Allow-Origin": "*"})

@app.route('/api/tts', methods=['POST', 'OPTIONS'])
def tts_handler():
    if request.method == 'OPTIONS':
        resp = make_response()
        resp.headers.add("Access-Control-Allow-Origin", "*")
        resp.headers.add("Access-Control-Allow-Headers", "*")
        return resp
    
    data = request.json or {}
    text = data.get('text', '')
    if not text: return jsonify({"error": "No text"}), 400
    
    # Simple cleanup
    clean_text = text.replace("*", "").replace("#", "").strip()[:4000]

    async def get_audio():
        # Using zh-CN-YunyangNeural for a more professional/master-like male voice
        communicate = edge_tts.Communicate(clean_text, "zh-CN-YunyangNeural")
        audio = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio += chunk["data"]
        return audio

    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        audio_data = loop.run_until_complete(get_audio())
        loop.close()
        return Response(audio_data, mimetype="audio/mpeg")
    except Exception as e:
        return jsonify({"error": str(e)}), 500

# --- Keep-Alive ä¿æŒé€£ç·šæ©Ÿåˆ¶ (é‡å° Render å…è²»ç‰ˆ) ---
def keep_alive_pinger():
    """å®šæœŸå°ä¼ºæœå™¨ç™¼é€è«‹æ±‚ï¼Œé˜²æ­¢å…è²»ç‰ˆé€²å…¥ä¼‘çœ ã€‚"""
    url = "https://fate-purple.onrender.com"  # è‡ªèº« URL
    print(f"ğŸš€ [ä¿æŒé€£ç·š] å•Ÿå‹•èƒŒæ™¯æ¢æ¸¬å™¨ï¼š{url}")
    while True:
        try:
            time.sleep(600)  # æ¯ 10 åˆ†é˜ (600s) ç™¼é€ä¸€æ¬¡
            print(f"â° [ä¿æŒé€£ç·š] æ¢æ¸¬æ™‚é–“ï¼š{datetime.now(timezone(timedelta(hours=8))).strftime('%H:%M:%S')}...")
            response = requests.get(url, timeout=10)
            print(f"âœ… [ä¿æŒé€£ç·š] æ¢æ¸¬æˆåŠŸï¼Œç‹€æ…‹ç¢¼ï¼š{response.status_code}")
        except Exception as e:
            print(f"âš ï¸ [ä¿æŒé€£ç·š] æ¢æ¸¬å¤±æ•—ï¼š{e}")
            time.sleep(60)

# åƒ…åœ¨ Render ç’°å¢ƒå•Ÿå‹•èƒŒæ™¯æ¢æ¸¬å™¨
if os.environ.get('RENDER'):
    threading.Thread(target=keep_alive_pinger, daemon=True).start()

if __name__ == '__main__':
    # æª¢æŸ¥æ˜¯å¦ç‚ºç„¡ä»‹é¢æ¨¡å¼ (ä¾‹å¦‚ Render, Docker, æˆ– GitHub Codespaces)
    if os.environ.get('HEADLESS') or os.environ.get('RENDER') or not HAS_TK:
        print("ç³»çµ±æ­£ä»¥ã€ç„¡ä»‹é¢æ¨¡å¼ã€‘å•Ÿå‹• (åƒ…ç¶²é ä¼ºæœå™¨)...")
        app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)), debug=False)
    else:
        # æœ¬åœ°æ¡Œé¢æ¨¡å¼ï¼ŒåŒ…å« Tkinter ä¸­æ§å°
        try:
            ui = BackendApp(app)
            ui.mainloop()
        except Exception as e:
            # å¦‚æœæ‰¾ä¸åˆ°é¡¯ç¤ºè¨­å‚™å‰‡é™ç´šé‹è¡Œ
            print(f"GUI å•Ÿå‹•å¤±æ•— ({e})ï¼Œæ­£åœ¨åˆ‡æ›ç‚ºã€ç„¡ä»‹é¢æ¨¡å¼ã€‘...")
            app.run(host="0.0.0.0", port=5000, debug=False)
