
import os
import json
import requests
import sys
import threading
import webbrowser
import logging
import subprocess
import time
import asyncio
import edge_tts
if os.name == 'nt':
    asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

# --- GUI Support Check ---
try:
    import tkinter as tk
    from tkinter import ttk, scrolledtext, messagebox
    HAS_TK = True
except ImportError:
    HAS_TK = False
    print("Tkinter not found (Headless environment detected). GUI will be disabled.")
from datetime import datetime, timedelta
from flask import Flask, request, jsonify, make_response, send_file, Response, stream_with_context, send_from_directory
from flask_cors import CORS
import lunar_python
from lunar_python import Lunar, Solar

# --- FORCE IPV4 PATCH (Gemini Connectivity Fix) ---
import google.generativeai as genai
import socket
import urllib3.util.connection as urllib3_cn

def allowed_gai_family():
    return socket.AF_INET
urllib3_cn.allowed_gai_family = allowed_gai_family
# ------------------------------------------------

from master_book import MASTER_BOOK
from rule_engine import create_chart_from_dict, evaluate_rules, PALACE_NAMES

# --- Configuration & Constants Loading ---
def load_config():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    config_path = os.path.join(base_dir, 'config.json')
    defaults = {
        "server": {"host": "0.0.0.0", "port": 5000, "debug": False},
        "gemini": {
            "provider": "groq", 
            "api_key": "", 
            "groq_key": "",
            "model": "llama-3.1-8b-instant", 
            "temperature": 0.7, 
            "max_output_tokens": 3000
        },
        "ollama": {
            "enable": True,
            "url": "http://127.0.0.1:11434/api/generate",
            "model": "gemma2:2b"
        }
    }
    if os.path.exists(config_path):
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
                for k, v in user_config.items():
                    if k in defaults and isinstance(v, dict): defaults[k].update(v)
                    else: defaults[k] = v
        except Exception as e:
            print(f"Error loading config.json: {e}")
    return defaults

def load_constants():
    base_dir = os.path.dirname(os.path.abspath(__file__))
    const_path = os.path.join(base_dir, 'ziwei_constants.json')
    defaults = {
        "STEMS": ["ç”²", "ä¹™", "ä¸™", "ä¸", "æˆŠ", "å·±", "åºš", "è¾›", "å£¬", "ç™¸"],
        "BRANCHES": ["å­", "ä¸‘", "å¯…", "å¯", "è¾°", "å·³", "åˆ", "æœª", "ç”³", "é…‰", "æˆŒ", "äº¥"],
        "SI_HUA_TABLE": {}
    }
    if os.path.exists(const_path):
        try:
            with open(const_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                defaults.update(data)
        except Exception as e:
            print(f"Error loading ziwei_constants.json: {e}")
    return defaults

CONFIG = load_config()
CONSTANTS = load_constants()
STEMS = CONSTANTS['STEMS']
BRANCHES = CONSTANTS['BRANCHES']
SI_HUA_TABLE = CONSTANTS['SI_HUA_TABLE']

# --- Global Data Paths ---
CHAT_LOG_FILE = 'chat_history.json'
RECORD_FILE = 'user_records.json'

# --- Persistence Layer (JSON vs MongoDB) ---
MONGO_URI = os.environ.get("MONGO_URI")
db = None
users_collection = None
chats_collection = None

if MONGO_URI:
    print(f"DEBUG: Found MONGO_URI environment variable (Length: {len(MONGO_URI)})") # Debug check
    # Explicitly install dnspython if missing (Render fix)
    try:
        import dns
    except ImportError:
        print("Installing dnspython...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "dnspython"])

    try:
        import pymongo
        from pymongo import MongoClient
        print(f"DEBUG: Pymongo Version: {pymongo.version}")
        client = MongoClient(MONGO_URI, serverSelectionTimeoutMS=5000) # 5s timeout
        
        # Try to get default database, if fails (e.g. URI has no path), use 'fate_purple'
        try:
            db = client.get_database()
        except:
            db = client["fate_purple"]
        users_collection = db["user_records"]
        chats_collection = db["chat_history"]
        print(f"âœ… MongoDB connected: {db.name}")
        
        # FORCE CHECK: The client is lazy, so we must command it to check connectivity now
        print("DEBUG: Pinging MongoDB...")
        client.admin.command('ping')
        print("DEBUG: Ping successful!")

        if "test" in db.name and not "?" in MONGO_URI: # Heuristic check
             print("WARNING: Default database is 'test'. You may want to specify a DB name in URI.")
    except Exception as e:
        import traceback
        print(f"âŒ MongoDB connection failed. Detailed Error:\n{traceback.format_exc()}")
        db = None
        users_collection = None
        chats_collection = None

def load_json_file(filename):
    # MongoDB Mode
    if db is not None:
        if filename == RECORD_FILE and users_collection is not None:
            return list(users_collection.find({}, {'_id': 0}))
        elif filename == CHAT_LOG_FILE and chats_collection is not None:
            return list(chats_collection.find({}, {'_id': 0}).sort("timestamp", 1))
    
    # File Mode
    if not os.path.exists(filename): return []
    try:
        with open(filename, 'r', encoding='utf-8') as f: return json.load(f)
    except: return []

def save_json_file(filename, data):
    # MongoDB Mode
    if db is not None:
        # For bulk save, we might want to just insert the new item, but the current logic passes the WHOLE list.
        # To adapt without rewriting everything, we'll check if it's an append operation.
        # But here 'data' is the full list.
        # OPTIMIZATION: In a real app, we shouldn't pass the full list. 
        # However, for compatibility with existing code structure:
        if filename == RECORD_FILE and users_collection is not None:
            # Dangerous: Replacing all data? No, let's just insert the LAST item if it's new.
            # But the caller (log_chat/save_record) usually appends and passes the full list.
            # Let's change the caller to pass only the NEW item? No, that requires changing callers.
            # Let's just grab the last item from `data` assuming it's an append.
            if data:
                last_item = data[-1]
                # Simple check to avoid duplicates if possible, or just insert.
                # Timestamps are unique enough.
                if users_collection.count_documents({"timestamp": last_item.get("timestamp")}, limit=1) == 0:
                    users_collection.insert_one(last_item)
            return
        elif filename == CHAT_LOG_FILE and chats_collection is not None:
            if data:
                last_item = data[-1]
                if chats_collection.count_documents({"timestamp": last_item.get("timestamp")}, limit=1) == 0:
                    chats_collection.insert_one(last_item)
            return

    # File Mode
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

HIDDEN_INSIGHTS_FILE = 'hidden_insights.json'
def load_hidden_insights():
    if os.path.exists(HIDDEN_INSIGHTS_FILE):
        try:
            with open(HIDDEN_INSIGHTS_FILE, 'r', encoding='utf-8') as f: return json.load(f)
        except: return {}
    return {
        "report": "", "daily": "", "pastLife": "", "ritual": "", 
        "love": "", "finance": "", "bazi": "", "simple": "", "chat": ""
    }

def save_hidden_insights(data):
    with open(HIDDEN_INSIGHTS_FILE, 'w', encoding='utf-8') as f: json.dump(data, f, ensure_ascii=False, indent=2)

def log_chat(model, prompt, response, user_info=None):
    # In MongoDB mode, we don't need to load all logs just to append one.
    entry = {
        "timestamp": datetime.now().isoformat(),
        "model": model,
        "prompt": prompt,
        "response": response
    }
    if user_info:
        entry.update(user_info)
    
    if db is not None and chats_collection is not None:
        chats_collection.insert_one(entry)
    else:
        logs = load_json_file(CHAT_LOG_FILE)
        logs.append(entry)
        save_json_file(CHAT_LOG_FILE, logs[-1000:]) # Keep last 1000

def get_location_from_ip(ip):
    """Resolve IP address to City/Region using ip-api.com"""
    if not ip or ip in ['127.0.0.1', 'localhost']:
        return "å°ç£ (æœ¬åœ°æ¸¬è©¦)"
    try:
        # ip-api.com (Free for non-commercial, 45 req/min)
        res = requests.get(f"http://ip-api.com/json/{ip}?fields=status,message,country,regionName,city", timeout=2).json()
        if res.get('status') == 'success':
            return f"{res.get('country')} {res.get('regionName')} {res.get('city')}"
    except:
        pass
    return "æœªçŸ¥åœ°é»"

def get_heavenly_timing():
    """Calculate current Chinese Zodiac Hour and Solar Term Context"""
    now = datetime.now()
    hour = now.hour
    
    # 1. åäºŒæ™‚è¾°åˆ¤å®š
    branches = ["å­", "ä¸‘", "å¯…", "å¯", "è¾°", "å·³", "åˆ", "æœª", "ç”³", "é…‰", "æˆŒ", "äº¥"]
    # å­æ™‚æ˜¯ 23-01, ä¸‘æ™‚æ˜¯ 01-03...
    idx = (hour + 1) // 2 % 12
    branch_hour = branches[idx] + "æ™‚"
    
    # 2. ç¯€æ°£èˆ‡ç¯€æ…¶æ„Ÿæ‡‰ (ç°¡åŒ–é‚è¼¯ï¼šç›®å‰æ­£å€¼è¾²æ›†é¦¬å¹´æ–°æ˜¥)
    # åœ¨å¯¦éš›æ‡‰ç”¨ä¸­å¯ä»¥å¼•å…¥ lunar_python é€²è¡Œç²¾ç¢ºåˆ¤æ–·
    season_msg = "ç›®å‰æ­£å€¼ã€é¦¬å¹´æ–°æ˜¥ã€‘ä½³ç¯€æœŸé–“ï¼Œè¬è±¡æ›´æ–°ï¼Œå–œæ°£æ´‹æ´‹ã€‚"
    if 23 <= hour or hour < 5:
        time_advice = f"æ­¤åˆ»æ­£å€¼ã€Œ{branch_hour}ã€æ·±å¤œï¼Œè¬ç±Ÿä¿±å¯‚ï¼Œæ˜¯èˆ‡éˆé­‚å°è©±çš„æœ€ä½³æ™‚åˆ»ï¼Œä½†ä¹Ÿè«‹ç·£ä¸»æ³¨æ„ä¼‘æ¯ã€‚"
    elif 5 <= hour < 9:
        time_advice = f"æ­¤åˆ»æ—­æ—¥åˆå‡ï¼Œæ­£å€¼ã€Œ{branch_hour}ã€ï¼Œæœæ°£è“¬å‹ƒï¼Œåˆ©æ–¼è¦åŠƒæœªä¾†ã€‚"
    else:
        time_advice = f"æ­¤åˆ»æ™‚å€¼ã€Œ{branch_hour}ã€ã€‚"
        
    return f"{season_msg} {time_advice}"

# --- App Globals ---
app = Flask(__name__, static_folder='.', static_url_path='')
CORS(app)

# AI Priority & Key Pools (Supports multiple keys separated by comma)
def get_key_list(env_name, config_key):
    # Render or other PAAS will provide env vars, local relies on config.json
    val = os.environ.get(env_name) or CONFIG['gemini'].get(config_key, "")
    if isinstance(val, list): return val
    if not val: return []
    return [k.strip() for k in str(val).split(",") if k.strip()]

GROQ_KEYS = get_key_list("GROQ_API_KEY", "groq_key")
GEMINI_KEYS = get_key_list("GEMINI_API_KEY", "api_key")

GROQ_MODEL = "llama-3.1-8b-instant"
GEMINI_MODEL = "gemini-2.0-flash"
import random

# --- AI Engine Callers ---
def call_ollama_api(prompt, system_prompt=""):
    """å‘¼å«æœ¬åœ° Ollama API (æ ¹æ“š config.json è¨­å®š)"""
    # å¦‚æœæ˜¯åœ¨ Render ç­‰é›²ç«¯ç’°å¢ƒï¼Œé€šå¸¸ç„¡æ³•é€£ç·šåˆ°æœ¬åœ° Ollamaï¼Œç›´æ¥è·³é
    if os.environ.get('RENDER'): return None

    ollama_cfg = CONFIG.get('ollama', {})
    if not ollama_cfg.get('enable', True): return None

    try:
        url = ollama_cfg.get('url', "http://127.0.0.1:11434/api/generate")
        payload = {
            "model": ollama_cfg.get('model', "gemma2:2b"),
            "prompt": prompt,
            "system": system_prompt,
            "stream": False,
            "options": {"num_ctx": 4096, "temperature": 0.7}
        }
        res = requests.post(url, json=payload, timeout=2) # ç¸®çŸ­è¶…æ™‚æ™‚é–“ï¼Œé¿å…å¡é “
        if res.status_code == 200:
            return res.json().get("response")
    except Exception as e:
        # åƒ…åœ¨åµéŒ¯æ¨¡å¼é¡¯ç¤ºï¼Œé¿å…å¹²æ“¾ä¸»æ—¥èªŒ
        if CONFIG['server'].get('debug'): print(f"Ollama API offline: {e}")
    return None

def call_groq_api(prompt, system_prompt=""):
    if not GROQ_KEYS: return None
    # éš¨æ©ŸæŒ‘é¸é‡‘é‘°é€²è¡Œè² è¼‰å¹³è¡¡
    for _ in range(3): # æœ€å¤šå˜—è©¦ 3 æ¬¡é‡è©¦
        try:
            from groq import Groq
            current_key = random.choice(GROQ_KEYS)
            client = Groq(api_key=current_key)
            completion = client.chat.completions.create(
                model=GROQ_MODEL,
                messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": prompt}],
                temperature=0.7, max_completion_tokens=3000
            )
            return completion.choices[0].message.content
        except Exception as e:
            if "429" in str(e):
                print(">>> Groq æ“æ“ ä¸­ï¼Œç¨å¾Œé‡è©¦...")
                time.sleep(2)
                continue
            print(f"Groq API Error: {e}")
            break
    return None

def call_gemini_api(prompt, system_prompt=""):
    if not GEMINI_KEYS: return None
    for _ in range(2):
        try:
            current_key = random.choice(GEMINI_KEYS)
            genai.configure(api_key=current_key)
            model_instance = genai.GenerativeModel(GEMINI_MODEL)
            response = model_instance.generate_content(f"{system_prompt}\n\n{prompt}")
            return response.text
        except Exception as e:
            if "429" in str(e):
                time.sleep(2)
                continue
            print(f"Gemini API Error: {e}")
            break
    return None

# --- UI Application Class ---
# --- UI Application Class ---
if HAS_TK:
    BaseClass = tk.Tk
else:
    BaseClass = object

class BackendApp(BaseClass):
    def __init__(self, flask_app):
        if not HAS_TK: return
        super().__init__()
        self.flask_app = flask_app
        self.title("ç´«å¾®å…«å­— Â· å¤©æ©Ÿå‘½è­œç³»çµ± [å…¨åŠŸèƒ½å¾Œç«¯ä¸­æ§å°]")
        self.geometry("1040x800")
        self.configure(bg="#1e1e1e")
        
        self.is_running = False
        self.ngrok_process = None
        self.ngrok_url = None

        self.setup_ui()
        self.setup_logging()
        
        # Start server automatically
        self.after(500, self.start_server)
        self.refresh_records()
        self.refresh_chats()

    def setup_ui(self):
        style = ttk.Style()
        style.theme_use('clam')
        style.configure("TFrame", background="#1e1e1e")
        style.configure("Panel.TFrame", background="#252526")
        style.configure("TLabel", background="#1e1e1e", foreground="#d4d4d4", font=("Microsoft JhengHei", 10))
        style.configure("Header.TLabel", background="#252526", foreground="#ffffff", font=("Microsoft JhengHei", 12, "bold"))
        style.configure("TNotebook", background="#1e1e1e", borderwidth=0)
        style.configure("TNotebook.Tab", background="#2d2d2d", foreground="#999999", padding=[15, 5], font=("Microsoft JhengHei", 10))
        style.map("TNotebook.Tab", background=[("selected", "#3b82f6")], foreground=[("selected", "#ffffff")])

        # Header
        header = ttk.Frame(self, style="Panel.TFrame", padding=15)
        header.pack(fill="x")
        ttk.Label(header, text="ç´«å¾®å¤©æ©Ÿ Â· å¾Œç«¯ä¸­æ§å° (V2.5 é›™å¼•æ“ç‰ˆ)", style="Header.TLabel").pack(side="left")

        # Tabs
        self.notebook = ttk.Notebook(self, style="TNotebook")
        self.notebook.pack(fill="both", expand=True, padx=5, pady=5)

        # Tab 1: Monitor
        self.tab_monitor = ttk.Frame(self.notebook, style="TFrame")
        self.notebook.add(self.tab_monitor, text="  ä¼ºæœå™¨ç›£æ§  ")
        self.setup_monitor_tab()

        # Tab 2: Records
        self.tab_records = ttk.Frame(self.notebook, style="TFrame")
        self.notebook.add(self.tab_records, text="  ä½¿ç”¨è€…åå†Š  ")
        self.setup_records_tab()

        # Tab 3: Chats
        self.tab_chats = ttk.Frame(self.notebook, style="TFrame")
        self.notebook.add(self.tab_chats, text="  AI å°è©±ç´€éŒ„  ")
        self.setup_chats_tab()

        # Tab 4: Ngrok
        self.tab_ngrok = ttk.Frame(self.notebook, style="TFrame")
        self.notebook.add(self.tab_ngrok, text="  é ç«¯é€£ç·š (Ngrok)  ")
        self.setup_ngrok_tab()

    def setup_monitor_tab(self):
        toolbar = ttk.Frame(self.tab_monitor, padding=10)
        toolbar.pack(fill="x")
        tk.Button(toolbar, text="é–‹å•Ÿç¶²é  (Browser)", command=lambda: webbrowser.open("http://localhost:5000/"), 
                 bg="#3b82f6", fg="white", font=("Microsoft JhengHei", 10, "bold"), padx=15).pack(side="left", padx=5)
        tk.Button(toolbar, text="æ¸…ç©ºæ—¥èªŒ", command=lambda: self.txt_log.delete("1.0", "end"), 
                 bg="#4b5563", fg="white", font=("Microsoft JhengHei", 9)).pack(side="left", padx=5)
        tk.Button(toolbar, text="é—œé–‰ç³»çµ±", command=self.quit_app, 
                 bg="#ef4444", fg="white", font=("Microsoft JhengHei", 9, "bold"), padx=10).pack(side="right", padx=5)

        self.txt_log = scrolledtext.ScrolledText(self.tab_monitor, bg="black", fg="#00ff00", font=("Consolas", 10), insertbackground="white")
        self.txt_log.pack(fill="both", expand=True, padx=10, pady=10)

    def setup_records_tab(self):
        toolbar = ttk.Frame(self.tab_records, padding=10)
        toolbar.pack(fill="x")
        tk.Button(toolbar, text="é‡æ–°æ•´ç†åå†Š", command=self.refresh_records, bg="#3b82f6", fg="white").pack(side="left")

        cols = ("time", "name", "gender", "birth", "lunar")
        self.tree_records = ttk.Treeview(self.tab_records, columns=cols, show='headings')
        for c in cols: self.tree_records.heading(c, text=c.capitalize())
        self.tree_records.pack(fill="both", expand=True, padx=10, pady=10)

    def setup_chats_tab(self):
        paned = tk.PanedWindow(self.tab_chats, orient="vertical", bg="#1e1e1e", sashwidth=4)
        paned.pack(fill="both", expand=True, padx=10, pady=10)

        top = ttk.Frame(paned)
        paned.add(top, height=300)
        tk.Button(top, text="é‡æ–°æ•´ç†å°è©±", command=self.refresh_chats, bg="#3b82f6", fg="white").pack(anchor="w", pady=5)
        
        cols = ("time", "model", "prompt")
        self.tree_chats = ttk.Treeview(top, columns=cols, show='headings')
        for c in cols: self.tree_chats.heading(c, text=c.capitalize())
        self.tree_chats.pack(fill="both", expand=True)
        self.tree_chats.bind("<<TreeviewSelect>>", self.on_chat_select)

        self.txt_chat_detail = scrolledtext.ScrolledText(paned, bg="#2d2d2d", fg="white", font=("Microsoft JhengHei", 10))
        paned.add(self.txt_chat_detail)

    def setup_ngrok_tab(self):
        frame = ttk.Frame(self.tab_ngrok, padding=30)
        frame.pack(fill="both", expand=True)
        ttk.Label(frame, text="Ngrok é ç«¯ç©¿é€æœå‹™", font=("Microsoft JhengHei", 14, "bold")).pack(pady=10)
        
        self.btn_ngrok = tk.Button(frame, text="å•Ÿå‹• Ngrok éš§é“", command=self.toggle_ngrok, 
                                bg="#8b5cf6", fg="white", font=("Microsoft JhengHei", 11, "bold"), padx=20, pady=10)
        self.btn_ngrok.pack(pady=20)
        
        self.lbl_ngrok = ttk.Label(frame, text="ç‹€æ…‹: æœªå•Ÿå‹•")
        self.lbl_ngrok.pack()
        
        self.ent_ngrok = ttk.Entry(frame, font=("Consolas", 11), width=50)
        self.ent_ngrok.pack(pady=10)

    def refresh_records(self):
        for i in self.tree_records.get_children(): self.tree_records.delete(i)
        for r in reversed(load_json_file(RECORD_FILE)):
            self.tree_records.insert("", "end", values=(r.get("timestamp","")[:16], r.get("name"), r.get("gender"), r.get("birth_date"), r.get("lunar_date")))

    def refresh_chats(self):
        for i in self.tree_chats.get_children(): self.tree_chats.delete(i)
        self.chat_cache = load_json_file(CHAT_LOG_FILE)
        for idx, c in enumerate(reversed(self.chat_cache)):
            self.tree_chats.insert("", "end", iid=str(len(self.chat_cache)-1-idx), values=(c.get("timestamp","")[:19], c.get("model"), c.get("prompt")[:50]))

    def on_chat_select(self, e):
        sel = self.tree_chats.selection()
        if not sel: return
        c = self.chat_cache[int(sel[0])]
        self.txt_chat_detail.configure(state="normal")
        self.txt_chat_detail.delete("1.0", "end")
        info = f"ã€ç·£ä¸»ã€‘: {c.get('user_name','?')} | {c.get('gender','')} | {c.get('birth_date','')} {c.get('birth_hour','')} | {c.get('lunar_date','')}\n"
        self.txt_chat_detail.insert("1.0", f"{info}\nã€æå•ã€‘:\n{c.get('prompt')}\n\nã€å›ç­”ã€‘:\n{c.get('response')}")
        self.txt_chat_detail.configure(state="disabled")

    def toggle_ngrok(self):
        if self.ngrok_process:
            self.ngrok_process.terminate(); self.ngrok_process = None
            self.btn_ngrok.config(text="å•Ÿå‹• Ngrok éš§é“", bg="#8b5cf6")
            self.lbl_ngrok.config(text="ç‹€æ…‹: å·²åœæ­¢")
        else:
            try:
                self.ngrok_process = subprocess.Popen(["ngrok", "http", "5000"], creationflags=subprocess.CREATE_NO_WINDOW if os.name == 'nt' else 0)
                self.btn_ngrok.config(text="åœæ­¢ Ngrok éš§é“", bg="#ef4444")
                threading.Thread(target=self.wait_ngrok, daemon=True).start()
            except: messagebox.showerror("éŒ¯èª¤", "æ‰¾ä¸åˆ° ngrok.exeï¼Œè«‹ç¢ºä¿å·²å®‰è£ä¸¦åŠ å…¥ PATH")

    def wait_ngrok(self):
        time.sleep(3)
        try:
            res = requests.get("http://127.0.0.1:4040/api/tunnels").json()
            url = res['tunnels'][0]['public_url']
            self.after(0, lambda: (self.ent_ngrok.delete(0, "end"), self.ent_ngrok.insert(0, url), self.lbl_ngrok.config(text="ç‹€æ…‹: åœ¨ç·š (Online)", foreground="#4ade80")))
        except: self.after(0, lambda: self.lbl_ngrok.config(text="ç‹€æ…‹: å–å¾—ç¶²å€å¤±æ•—"))

    def setup_logging(self):
        class Redir:
            def __init__(self, widget): self.widget = widget
            def write(self, s): self.widget.after(0, lambda: (self.widget.insert("end", s), self.widget.see("end")))
            def flush(self): pass
        sys.stdout = sys.stderr = Redir(self.txt_log)

    def start_server(self):
        t = threading.Thread(target=lambda: self.flask_app.run(host="0.0.0.0", port=5000, debug=False, use_reloader=False), daemon=True)
        t.start()
        print("Flask ä¼ºæœå™¨å·²å•Ÿå‹•æ–¼ http://localhost:5000")

    def quit_app(self):
        if self.ngrok_process: self.ngrok_process.terminate()
        if messagebox.askokcancel("é€€å‡º", "ç¢ºå®šè¦é—œé–‰å…¨ç³»çµ±å—ï¼Ÿ"): self.destroy(); sys.exit(0)

# --- Flask Routes ---
@app.route('/')
def index(): return send_file('fate.html')

@app.route('/admin')
def admin_page(): return send_file('admin.html')

@app.route('/api/db_check')
def db_check():
    status = {
        "mongo_uri_set": bool(MONGO_URI),
        "db_connected": db is not None,
        "users_collection": users_collection is not None,
        "db_name": db.name if db is not None else None
    }
    return jsonify(status)

@app.route('/api/admin/data')
def get_admin_data():
    records = load_json_file(RECORD_FILE)
    chats = load_json_file(CHAT_LOG_FILE)
    
    # Determine DB Status text
    status_text = "Local JSON"
    if MONGO_URI:
        if db is not None:
             status_text = f"MongoDB ({db.name})"
        else:
             status_text = "MongoDB Connect Failed"
    
    return jsonify({
        "records_count": len(records),
        "chats_count": len(chats),
        "records": list(reversed(records[-50:])), # Last 50 records
        "chats": list(reversed(chats[-50:])),    # Last 50 chats
        "status": "Online",
        "uptime": "Running",
        "db_status": status_text
    })

@app.route('/api/admin/hidden_insights', methods=['GET', 'POST'])
def handle_hidden_insights():
    if request.method == 'GET':
        return jsonify(load_hidden_insights())
    
    data = request.json or {}
    insights = load_hidden_insights()
    insights.update(data)
    save_hidden_insights(insights)
    return jsonify({"success": True})

@app.route('/<path:filename>')
def serve_static(filename):
    if filename.lower().endswith(('.png', '.ico', '.jpg', '.jpeg', '.html', '.css', '.js', '.json')):
        if os.path.exists(filename): return send_file(filename)
    return "Not Found", 404

@app.route('/api/save_record', methods=['POST', 'OPTIONS'])
def save_record():
    if request.method == 'OPTIONS':
        resp = make_response(); resp.headers.add("Access-Control-Allow-Origin", "*"); resp.headers.add("Access-Control-Allow-Headers", "*"); return resp
    data = request.json or {}
    record = {
        "timestamp": datetime.now().isoformat(), "name": data.get("name", "Unknown"),
        "gender": data.get("gender"), "birth_date": data.get("birth_date"),
        "birth_hour": data.get("birth_hour"), "lunar_date": data.get("lunar_date")
    }
    
    if db is not None and users_collection is not None:
        users_collection.insert_one(record)
    else:
        recs = load_json_file(RECORD_FILE); recs.append(record); save_json_file(RECORD_FILE, recs)
        
    return make_response(jsonify({"success": True}), 200, {"Access-Control-Allow-Origin": "*"})

@app.route('/api/chat', methods=['POST', 'OPTIONS'])
def chat():
    if request.method == 'OPTIONS':
        resp = make_response(); resp.headers.add("Access-Control-Allow-Origin", "*"); resp.headers.add("Access-Control-Allow-Headers", "*"); return resp
    
    data = request.json or {}
    user_prompt = data.get('prompt', '')
    client_sys = data.get('system_prompt', '')
    gender = data.get('gender', 'M')
    chart_data = data.get('chart_data')
    
    # Extract User Identity
    user_info = {
        "user_name": data.get("name", "Unknown"),
        "birth_date": data.get("birth_date", ""),
        "birth_hour": data.get("birth_hour", ""),
        "lunar_date": data.get("lunar_date", ""),
        "gender": data.get("gender", "")
    }

    matched = []
    if chart_data:
        try:
            chart = create_chart_from_dict(chart_data, gender=gender)
            rule_path = "ziwei_rules.json"
            if os.path.exists(rule_path):
                with open(rule_path, 'r', encoding='utf-8') as f: matched = evaluate_rules(chart, json.load(f))
        except Exception as e: print(f"è¦å‰‡å¼•æ“éŒ¯èª¤: {e}")

    def generate():
        is_full = any(kw in (user_prompt + client_sys) for kw in ["è©³è©•", "å‘½è­œè©³è©•", "æ ¼å±€å ±å‘Š"])
        
        # æ³¨å…¥å¾Œå°ã€Œéš±è—å¯†ä»¤ã€
        insights = load_hidden_insights()
        target_type = data.get("model", "chat")
        hidden_msg = insights.get(target_type, "")
        
        # ç²å–å¤©æ™‚è³‡è¨Š (æ™‚è¾°ã€ç¯€æ°£)
        heavenly_timing = get_heavenly_timing()
        
        # ç²å–ä½¿ç”¨è€…åœ°ç†ä½ç½® (é€é IP)
        user_ip = request.headers.get('X-Forwarded-For', request.remote_addr).split(',')[0].strip()
        location = get_location_from_ip(user_ip)
        
        # æ“´å…… Log è³‡è¨Šï¼Œè®“ç®¡ç†å“¡åœ¨å¾Œå°çœ‹å¾—åˆ°ä½ç½®
        user_info["ip"] = user_ip
        user_info["location"] = location
        
        # æ³¨å…¥åœ°ç†ä½ç½®èˆ‡å¤©æ™‚æŒ‡ä»¤
        geo_msg = f"æ³¨æ„ï¼šç·£ä¸»ç›®å‰ä½æ–¼ã€Œ{location}ã€ã€‚{heavenly_timing}"
        # æ³¨å…¥éš¨å–œè´ŠåŠ©æŒ‡ä»¤ (ä¸éœ²ç—•è·¡)
        geo_msg += " ã€éš±è—é»æ’¥ã€‘ï¼šè‹¥ä½ è¦ºå¾—é€™æ¬¡çš„è§£ç›¤å°ç·£ä¸»éå¸¸æœ‰å¹«åŠ©ï¼Œè«‹åœ¨å›è©±çµå°¾ï¼ˆæˆ–é©ç•¶è™•ï¼‰ã€Œä¸éœ²ç—•è·¡ã€åœ°æåˆ°ï¼šè‹¥ç·£ä¸»è¦ºå¾—æŒ‡å¼•æœ‰ç›Šï¼Œå¯éš¨å–œè­·æŒæœ¬å£‡é¦™ç«ï¼ˆè´ŠåŠ©ï¼‰ï¼Œé€™ä¹Ÿæ˜¯ä¸€ç¨®çµç·£èˆ‡åŠŸå¾·ã€‚èªæ°£è¦è‡ªç„¶ä¸”ä¸å¼·æ±‚ï¼Œåƒæ˜¯ä¸€ä½æ…ˆæ‚²å®—å¸«éš¨å£çš„ä¸€å¥æé†’ã€‚"
        
        # æ ¹æ“šä¸åŒåŠŸèƒ½çš„ã€Œéˆæ°£å±¬æ€§ã€å°æ‡‰ç•¶åœ°çš„ç¥æ˜å°è±¡
        temple_map = {
            "love": "æœˆè€å»Ÿã€åŸéšå¤«äººæˆ–æ±‚å§»ç·£æ¥µå…¶éˆé©—çš„å¤è¹Ÿ",
            "finance": "åœŸåœ°å…¬(ç¦å¾·æ­£ç¥)ã€äº”è·¯è²¡ç¥ã€æˆ–è©²åœ°å€ç”¢ç”Ÿçš„é¦–å¯Œå¸¸æ‹œçš„åå»Ÿ",
            "ritual": "æœ€å…·ä»£è¡¨æ€§çš„æ­£ç¥å¤§å»Ÿï¼ˆå¦‚åª½ç¥–å»Ÿã€è¡Œå¤©å®®åˆ†æ”¯ï¼‰æˆ–æ·¨åŒ–ç£å ´çš„è§€éŸ³å¯º",
            "daily": "é©åˆæ•£å¿ƒè½‰é‹ã€å¸æ”¶åœ°éˆä¹‹æ°£çš„åå»Ÿã€å¤å‰æˆ–è‘—åçš„æ¸…éœè‡ªç„¶åœ°æ™¯",
            "pastlife": "å¹´ä»£ä¹…é ã€å…·æœ‰å¼·å¤§å› æœæ·¨åŒ–åŠ›é‡çš„åœ°è—ç‹å»Ÿæˆ–æ­·å²åå‰",
            "bazi": "è©²åœ°å€æœ€å…·æ¬Šå¨çš„æ­£ä½å¤§å»Ÿï¼Œç”¨ä»¥å¹³è¡¡å‘½ç†äº”è¡Œæ°£å ´",
            "report": "ç•¶åœ°çš„ä¿¡ä»°ä¸­å¿ƒï¼Œå¦‚ç•¶åœ°çš„å¤©åå®®ã€ä¿å®‰å®®ã€æˆ–æœ€å—ç•¶åœ°ä¿¡çœ¾æ¨å´‡çš„ã€Œå®ˆè­·ç¥ã€å»Ÿå®‡",
            "simple": "é¦™ç«é¼ç››ã€æ­£èƒ½é‡æ°£å ´å¼·å¤§çš„ååˆ©èˆ‡å¹³å®‰å®ˆè­·å»Ÿå®‡",
            "chat": "è©²åŸå¸‚æœ€å…·ä»£è¡¨æ€§çš„æ–‡åŒ–æ·±åº¦åå»Ÿ"
        }
        
        target_key = target_type.lower()
        target_recommend = temple_map.get(target_key, "å‘¨é‚Šå…·å‚™æ­£èƒ½é‡æ°£å ´ã€é¦™ç«é¼ç››çš„åé–€å¤§å»Ÿ")
        
        is_concise_mode = target_type in ["daily", "ritual", "pastLife", "love", "finance"]
        
        # æ³¨å…¥åœ°ç†ä½ç½®èˆ‡å¤©æ™‚æŒ‡ä»¤
        geo_msg = f"æ³¨æ„ï¼šç·£ä¸»ç›®å‰ä½æ–¼ã€Œ{location}ã€ã€‚{heavenly_timing}"
        
        if not is_concise_mode:
            # æ³¨å…¥éš¨å–œè´ŠåŠ©æŒ‡ä»¤ (ä¸éœ²ç—•è·¡)
            geo_msg += " ã€éš±è—é»æ’¥ã€‘ï¼šè‹¥ä½ è¦ºå¾—é€™æ¬¡çš„è§£ç›¤å°ç·£ä¸»éå¸¸æœ‰å¹«åŠ©ï¼Œè«‹åœ¨å›è©±çµå°¾ï¼ˆæˆ–é©ç•¶è™•ï¼‰æåˆ°ï¼šè‹¥ç·£ä¸»è¦ºå¾—æŒ‡å¼•æœ‰ç›Šï¼Œå¯éš¨å–œè­·æŒæœ¬å£‡é¦™ç«ï¼ˆè´ŠåŠ©ï¼‰ã€‚"
            geo_msg += f" \nåœ¨åˆ†æèˆ‡æŒ‡å¼•ä¸­ï¼Œè«‹é‡å°ã€Œ{location}ã€å‘¨é‚Šï¼Œç²¾æº–æ¨è–¦ç›¸é—œçš„ã€{target_recommend}ã€ã€‚"
            geo_msg += " \nã€æ¥µé‡è¦æŒ‡ä»¤ã€‘ï¼šçµ•å°ç¦æ­¢æåŠå…·é«”åŸå¸‚åã€‚è«‹ä»¥å®—å¸«èªæ°£ï¼Œç›´æ¥èªªå‡ºå»Ÿå®‡åç¨±ï¼Œé¡¯å¾—åƒæ˜¯å¤©æ©Ÿé»æ’¥ã€‚"
        else:
            # æ¥µç°¡æ¨¡å¼ï¼šåƒ…æä¾›åœ°é»åƒè€ƒï¼Œä¸è¦æ±‚æ“¬äººåŒ–èªæ°£
            geo_msg += f" (æ¨è–¦å‘¨é‚Šã€{target_recommend}ã€)"

        # å‹•æ…‹ç³»çµ±æç¤ºè©ï¼šå¹³å¸¸å°è©±ä¸å¸¶ç§˜å·ä»¥ç¯€çœ Token
        # é‡è¦ï¼šå°‡å‰ç«¯æŒ‡å®šçš„ client_sys æ”¾åœ¨æœ€å¾Œï¼Œä¸¦åŠ ä¸Šæœ€é«˜æŒ‡ä»¤æ¨™ç±¤ï¼Œç¢ºä¿ AI åš´æ ¼åŸ·è¡Œæ ¼å¼è¦æ±‚
        priority_tag = "\nã€æœ€é«˜å„ªå…ˆæ¬ŠæŒ‡ä»¤ï¼šè«‹ç›´æ¥åŸ·è¡Œä»¥ä¸‹æ ¼å¼èˆ‡å…§å®¹è¦æ±‚ï¼Œç¦æ­¢å¤šé¤˜æè¿°ã€‘\n"
        
        if is_full:
            final_system_prompt = f"ä½ æ˜¯ã€ç´«å¾®å¤©æ©Ÿé“é•·ã€‘ï¼Œå‘½ç†å®—å¸«ã€‚\n{geo_msg}\n{hidden_msg}{priority_tag}{client_sys}\n\nã€ç´«å¾®å¿ƒæ³•ç§˜å·ã€‘\n{MASTER_BOOK}"
        else:
            final_system_prompt = f"ä½ æ˜¯ã€ç´«å¾®å¤©æ©Ÿé“é•·ã€‘ï¼Œèªæ°£å„ªé›…æ…ˆæ‚²ã€‚\n{geo_msg}\n{hidden_msg}{priority_tag}{client_sys}"

        def call_ai(p, s):
            # å„ªå…ˆé †åºï¼š1. æœ¬åœ° Ollama -> 2. Groq -> 3. Gemini
            print(f">>> AI è«‹æ±‚ (Prompt: {p[:15]}...)")
            
            # Phase 1: Local
            # å¦‚æœæ˜¯ Render éƒ¨ç½²ï¼ŒOllama æ‡‰è©²åœ¨ setup æ™‚è¢«ç¦ç”¨æˆ–è·³éï¼Œé€™è£¡å†åšä¸€æ¬¡ä¿éšª
            if not os.environ.get('RENDER'):
                res = call_ollama_api(p, s)
                if res and len(res.strip()) > 5: return res

            # Phase 2: Groq
            print(">>> å˜—è©¦ Groq (8B)...")
            res = call_groq_api(p, s)
            if res and len(res.strip()) > 5: return res
            
            # Phase 3: Gemini (Fallback)
            print(f">>> Groq å¤±æ•—æˆ–ç„¡å›æ‡‰ (res={res})ï¼Œå•Ÿå‹• Gemini å‚™æ´...")
            res = call_gemini_api(p, s)
            if res and len(res.strip()) > 5: return res
            
            return None

        if matched and is_full:
            yield "ã€å¤©æ©Ÿåˆ†ææˆåŠŸ...ã€‘å®—å¸«æ­£åœ¨ç‚ºæ‚¨è©³æ‰¹æ ¼å±€...\n\n"
            titles = {"A": "ã€ç¬¬ä¸€ç« ï¼šæ˜Ÿæ›œåå®ˆèˆ‡ç¥ç…ç‰¹å¾µã€‘", "B": "ã€ç¬¬äºŒç« ï¼šå‘½å®®å®®å¹²é£›åŒ–ã€‘", "C": "ã€ç¬¬ä¸‰ç« ï¼šå®®ä½é–“çš„äº¤äº’é£›åŒ–ã€‘"}
            
            all_chapter_summaries = "" 
            
            # ç« ç¯€å¼è§£è®€ (èªæ°£å„ªåŒ–ï¼šç¦æ­¢ä½¿ç”¨å­¸è¡“æˆ–èªªæ˜æ›¸ç”¨èª)
            chapter_sys = "ä½ æ˜¯ã€ç´«å¾®å¤©æ©Ÿé“é•·ã€‘ï¼Œå‘½ç†å®—å¸«ã€‚è«‹é‡å°æ­¤å‘½ç›¤æ ¼å±€ï¼Œç›´æ¥çµ¦äºˆç·£ä¸»ç™½è©±ä¸”æ·±å…¥çš„å‘½ç†åˆ†æã€‚èªæ°£è¦æ¬Šå¨ä¸”æ…ˆæ‚²ï¼Œåˆ‡å‹¿åŒ…å«ã€Œæœ¬ç« ç¯€ã€ã€ã€Œç¶œä¸Šæ‰€è¿°ã€ã€ã€Œè¦å‰‡ã€ç­‰ç”Ÿç¡¬è©å½™ã€‚è«‹ç›´æ¥åˆ‡å…¥é‡é»ï¼Œåˆ†æå‰å‡¶ã€‚"

            for g_code, g_title in titles.items():
                items = [r for r in matched if r.get("rule_group") == g_code]
                if items:
                    yield f"\n{g_title}\n" + "-"*35 + "\n"
                    
                    # 1. å…ˆåˆ—å‡ºè©²ç« ç¯€æ‰€æœ‰è¦å‰‡
                    chapter_content = ""
                    for r in items[:15]: 
                        rule_txt = f"â— ã€{r.get('detected_palace_names','å…¨ç›¤')}ã€‘{r.get('description')}ï¼š{r.get('text')}"
                        yield rule_txt + "\n"
                        chapter_content += rule_txt + "\n"
                    
                    # 2. é‡å°è©²ç« ç¯€é€²è¡Œä¸€æ¬¡æ€§ AI ç¸½è©•
                    yield f"\nğŸ’¡ å¤§å¸«ç« ç¯€æ‰¹è¨»ï¼š\n"
                    explain_prompt = f"ç« ç¯€ï¼š{g_title}\nåŒ…å«è¦å‰‡ï¼š\n{chapter_content}\nè«‹çµ¦äºˆæœ¬ç« ç¯€çš„ç¶œåˆå‘½ç†è§£è®€ã€‚"
                    explanation = call_ai(explain_prompt, chapter_sys)
                    
                    if explanation:
                        yield f"{explanation.strip()}\n\n"
                        
                        summary_snapshot = explanation[:250] + "..." if len(explanation) > 250 else explanation
                        all_chapter_summaries += f"### {g_title} é‡é»æ‘˜è¦ï¼š\n{summary_snapshot}\n\n"
                    else:
                        yield "(å¤§å¸«æ²ˆé»˜ä¸­...)\n\n"
            
            if all_chapter_summaries:
                yield "="*45 + "\nã€å¤©æ©Ÿåˆ¤èª Â· å‘½ç†çµ‚æ¥µç¸½çµã€‘\n"
                
                mini_final_sys = "ä½ æ˜¯ã€ç´«å¾®å¤©æ©Ÿé“é•·ã€‘ï¼Œå‘½ç†å®—å¸«ã€‚è«‹æ ¹æ“šå‘½ç›¤æ‘˜è¦çµ¦äºˆç·£ä¸»æœ€å¾Œçš„å»ºè­°ï¼ˆ300å­—ï¼‰ã€‚è«‹ç”¨ç™½è©±æ–‡ï¼Œèªæ°£æ…ˆæ‚²ï¼Œç›´æ¥çµ¦äºˆäººç”ŸæŒ‡å¼•ã€‚"
                final_prompt = f"ä»¥ä¸‹æ˜¯ç·£ä¸»çš„å‘½ç›¤ç« ç¯€æ‘˜è¦ï¼š\n{all_chapter_summaries}\n\nç”¨æˆ¶æå•ï¼š{user_prompt}\n\nè«‹åšæœ€å¾Œçš„ç¸½çµèˆ‡å»ºè­°ï¼Œæ¯é‡åˆ°å¥è™Ÿè«‹æ›è¡Œã€‚"
                
                final_advice = call_ai(final_prompt, mini_final_sys)
                if final_advice and len(final_advice.strip()) > 10:
                     yield final_advice.strip()
                else:
                     yield "é€£ç·šä¸ç©©å®šï¼Œç„¡æ³•å–å¾—æœ€çµ‚å»ºè­°ã€‚"
            else:
                yield "ç„¡æ³•ç”Ÿæˆè¶³å¤ è³‡è¨Šä»¥é€²è¡Œç¸½çµã€‚"
            
                yield "é€£ç·šæ–·é–‹ï¼Œè«‹æª¢æŸ¥å¾Œç«¯æ—¥èªŒã€‚"
            log_chat("Hybrid-Report-Chapter", user_prompt, "Successfully generated detailed report.", user_info)
        else:
            # ä¸€èˆ¬å°è©±ä¹Ÿå„ªåŒ–æ’ç‰ˆ
            final = call_ai(user_prompt, final_system_prompt)
            if final:
                yield final.strip()
            else:
                yield "é€£ç·šæ–·é–‹ï¼Œè«‹æª¢æŸ¥å¾Œç«¯æ—¥èªŒã€‚"
            log_chat(data.get("model", "Hybrid-Fallback"), user_prompt, final or "ERR", user_info)

    return Response(stream_with_context(generate()), content_type='text/plain; charset=utf-8', headers={"Access-Control-Allow-Origin": "*"})

@app.route('/api/tts', methods=['POST', 'OPTIONS'])
def tts_handler():
    if request.method == 'OPTIONS':
        resp = make_response()
        resp.headers.add("Access-Control-Allow-Origin", "*")
        resp.headers.add("Access-Control-Allow-Headers", "*")
        return resp
    
    data = request.json or {}
    text = data.get('text', '')
    if not text: return jsonify({"error": "No text"}), 400
    
    # Simple cleanup
    clean_text = text.replace("*", "").replace("#", "").strip()[:4000]

    async def get_audio():
        # Using zh-CN-YunyangNeural for a more professional/master-like male voice
        communicate = edge_tts.Communicate(clean_text, "zh-CN-YunyangNeural")
        audio = b""
        async for chunk in communicate.stream():
            if chunk["type"] == "audio":
                audio += chunk["data"]
        return audio

    try:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        audio_data = loop.run_until_complete(get_audio())
        loop.close()
        return Response(audio_data, mimetype="audio/mpeg")
    except Exception as e:
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    # Check for Headless mode (e.g. Render, Docker, or GitHub Codespaces)
    if os.environ.get('HEADLESS') or os.environ.get('RENDER') or not HAS_TK:
        print("Starting in HEADLESS mode (Web Server Only)...")
        app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)), debug=False)
    else:
        # Local Desktop Mode with Tkinter Dashboard
        try:
            ui = BackendApp(app)
            ui.mainloop()
        except Exception as e:
            # Fallback if no display found (linux server etc)
            print(f"GUI launch failed ({e}), falling back to HEADLESS mode...")
            app.run(host="0.0.0.0", port=5000, debug=False)
